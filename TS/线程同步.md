本文总结了进程同步的常用方法。



# 概括

## 线程

现在我们来讨论一下 Linux 中的线程，线程是轻量级的进程，想必这句话你已经听过很多次了，`轻量级`体现在所有的进程切换都需要清除所有的表、进程间的共享信息也比较麻烦，一般来说通过管道或者共享内存，如果是 fork 函数后的父子进程则使用共享文件，然而线程切换不需要像进程一样具有昂贵的开销，而且线程通信起来也更方便。线程分为两种：用户级线程和内核级线程

### 用户级线程

用户级线程避免使用内核，通常，每个线程会显示调用开关，发送信号或者执行某种切换操作来放弃 CPU，同样，计时器可以强制进行开关，用户线程的切换速度通常比内核线程快很多。在用户级别实现线程会有一个问题，即单个线程可能会垄断 CPU 时间片，导致其他线程无法执行从而 `饿死`。如果执行一个 I/O 操作，那么 I/O 会阻塞，其他线程也无法运行。

![图片](https://mmbiz.qpic.cn/mmbiz_png/A3ibcic1Xe0iaRQzFQFGQcETRPzYXnxtWOtKyhzS8jyhliakaUUuNxeFg6grxWyNkgBZsOss4WhgcvhhACdtjzhiaiaQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

一种解决方案是，一些用户级的线程包解决了这个问题。可以使用时钟周期的监视器来控制第一时间时间片独占。然后，一些库通过特殊的包装来解决系统调用的 I/O 阻塞问题，或者可以为非阻塞 I/O 编写任务。

### 内核级线程

内核级线程通常使用几个进程表在内核中实现，每个任务都会对应一个进程表。在这种情况下，内核会在每个进程的时间片内调度每个线程。

![图片](https://mmbiz.qpic.cn/mmbiz_png/A3ibcic1Xe0iaRQzFQFGQcETRPzYXnxtWOt5BCuQ5qDL0nic412MZLJXr7y6j8MkG15Wictw6PEmMPOoMK5A2t345dQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

所有能够阻塞的调用都会通过系统调用的方式来实现，当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。

从用户空间 -> 内核空间 -> 用户空间的开销比较大，但是线程初始化的时间损耗可以忽略不计。这种实现的好处是由时钟决定线程切换时间，因此不太可能将时间片与任务中的其他线程占用时间绑定到一起。同样，I/O 阻塞也不是问题。

### 混合实现

结合用户空间和内核空间的优点，设计人员采用了一种`内核级线程`的方式，然后将用户级线程与某些或者全部内核线程多路复用起来

![图片](https://mmbiz.qpic.cn/mmbiz_png/A3ibcic1Xe0iaRQzFQFGQcETRPzYXnxtWOtibHUBALDR6SFTzX0AXrPmTzzyOjjBVRclyMNuO2IIooUQGAjjWN32jQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。



## 线程通信

线程间的通信有两种情况：

1、一个进程中的线程与另外一个进程中的线程通信，由于两个线程只能访问自己所属进程的地址空间和资源，故等同于进程间的通信。

2、同一个进程中的两个线程进行通信。本文说的就是第二种情况。

关于进程间通信（IPC）可以看我的另一篇博文

http://blog.csdn.net/a987073381/article/details/52006729
比起进程复杂的通信机制（管道、匿名管道、消息队列、信号量、共享内存、内存映射以及socket等），线程间通信要简单的多。

因为同一进程的不同线程共享同一份全局内存区域，其中包括初始化数据段、未初始化数据段，以及堆内存段，所以线程之间可以方便、快速地共享信息。只需要将数据复制到共享（全局或堆）变量中即可。不过，要避免出现多个线程试图同时修改同一份信息。

下图为多线程的进程地址空间：

![img](https://img-blog.csdn.net/20160728220621387?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

线程安全：

所在的进程中有多个线程在同时运行，而这些线程可能会同时某一段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。线程安全就是说多线程访问同一段代码不会产生不确定的结果。编写线程安全的代码依靠 线程同步。

线程间的同步：

如果变量时只读的，多个线程同时读取该变量不会有一致性问题，但是，当一个线程可以修改的变量，其他线程也可以读取或者修改的时候，我们就需要对这些线程进行同步，确保它们在访问变量的存储内容时不会访问到无效的值。


Linux下提供了多种方式来处理线程同步，最常用的是互斥锁、条件变量、信号量和读写锁。 



用得最多的是互斥锁和条件变量。



#  互斥锁（mutex）



[linux中实现线程同步的6种方法](https://blog.csdn.net/u022812849/article/details/109225200)

[[linux c 线程间同步（通信）的几种方法--互斥锁，条件变量，信号量，读写锁](https://www.cnblogs.com/wsw-seu/p/8036218.html)

[[互斥锁pthread_mutex_init()函数](https://www.cnblogs.com/eustoma/p/10054783.html)](https://www.cnblogs.com/eustoma/p/10054783.html)



互斥锁本质就是一个特殊的全局变量，拥有lock和unlock两种状态，unlock的互斥锁可以由某个线程获得，当互斥锁由某个线程持有后，这个互斥锁会锁上变成lock状态，此后只有该线程有权力打开该锁，其他想要获得该互斥锁的线程都会阻塞，直到互斥锁被解锁。

锁机制是同一时刻只允许一个线程执行一个关键部分的代码。

互斥锁的类型：

+ 普通锁（PTHREAD_MUTEX_NORMAL）：互斥锁默认类型。当一个线程对一个普通锁加锁以后，其余请求该锁的线程将形成一个 等待队列，并在该锁解锁后按照优先级获得它，这种锁类型保证了资源分配的公平性。一个 线程如果对一个已经加锁的普通锁再次加锁，将引发死锁；对一个已经被其他线程加锁的普 通锁解锁，或者对一个已经解锁的普通锁再次解锁，将导致不可预期的后果。

+ 检错锁（PTHREAD_MUTEX_ERRORCHECK）：一个线程如果对一个已经加锁的检错锁再次加锁，则加锁操作返回EDEADLK；对一个已 经被其他线程加锁的检错锁解锁或者对一个已经解锁的检错锁再次解锁，则解锁操作返回 EPERM。

+ 嵌套锁（PTHREAD_MUTEX_RECURSIVE）：该锁允许一个线程在释放锁之前多次对它加锁而不发生死锁；其他线程要获得这个锁，则当前锁的拥有者必须执行多次解锁操作；对一个已经被其他线程加锁的嵌套锁解锁，或者对一个已经解锁的嵌套锁再次解锁，则解锁操作返回EPERM。

+ 默认锁（PTHREAD_MUTEX_ DEFAULT）：一个线程如果对一个已经加锁的默认锁再次加锁，或者虽一个已经被其他线程加锁的默 认锁解锁，或者对一个解锁的默认锁解锁，将导致不可预期的后果；这种锁实现的时候可能 被映射成上述三种锁之一。

相关方法：

```c

/*
有两种方法创建互斥锁，静态方式和动态方式。POSIX定义了一个宏PTHREAD_MUTEX_INITIALIZER来静态初始化互斥锁，方法如下：
*/

// 静态方式创建互斥锁,在LinuxThreads实现中，pthread_mutex_t是一个结构，而PTHREAD_MUTEX_INITIALIZER则是一个结构常量。
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; 

//动态方式是采用pthread_mutex_init()函数来初始化互斥锁，API定义如下：
// 动态方式创建互斥锁，其中参数mutexattr用于指定互斥锁的类型，具体类型见上面四种，如果为NULL，就是普通锁。
int pthread_mutex_init (pthread_mutex_t* mutex,const pthread_mutexattr_t* mutexattr);
// 其中mutexattr用于指定互斥锁属性（见下），如果为NULL则使用缺省属性。
// 互斥锁的属性在创建锁的时候指定，在LinuxThreads实现中仅有一个锁类型属性，不同的锁类型在试图对一个已经被锁定的互斥锁加锁时表现不同。当前（glibc2.2.3,linuxthreads0.9）有四个值可供选择：

/*
1.  PTHREAD_MUTEX_TIMED_NP，这是缺省值，也就是普通锁。当一个线程加锁以后，其余请求锁的线程将形成一个等待队列，并在解锁后按优先级获得锁。这种锁策略保证了资源分配的公平性。
2.  PTHREAD_MUTEX_RECURSIVE_NP，嵌套锁，允许同一个线程对同一个锁成功获得多次，并通过多次unlock解锁。如果是不同线程请求，则在加锁线程解锁时重新竞争。
3.  PTHREAD_MUTEX_ERRORCHECK_NP，检错锁，如果同一个线程请求同一个锁，则返回EDEADLK，否则与PTHREAD_MUTEX_TIMED_NP类型动作相同。这样保证当不允许多次加锁时不出现最简单情况下的死锁。
4.  PTHREAD_MUTEX_ADAPTIVE_NP，适应锁，动作最简单的锁类型，仅等待解锁后重新竞争。
*/



int pthread_mutex_lock(pthread_mutex_t *mutex); // 加锁，阻塞

//该函数语义与 pthread_mutex_lock() 类似，不同的是在锁已经被占据时返回 EBUSY 而不是挂起等待。
int pthread_mutex_trylock(pthread_mutex_t *mutex); // 尝试加锁，非阻塞

//解锁（要求锁是lock状态,并且由加锁线程解锁）
int pthread_mutex_unlock(pthread_mutex_t *mutex); // 解锁

//销毁锁（此时锁必需unlock状态,否则返回EBUSY）
int pthread_mutex_destroy(pthread_mutex *mutex);

```

例子：

```c
#include<stdio.h>
#include<pthread.h>

int ticket_num=10000000;

pthread_mutex_t mutex=PTHREAD_MUTEX_INITIALIZER;

void *sell_ticket(void *arg) {
    while(ticket_num>0) {
	pthread_mutex_lock(&mutex);
	if(ticket_num>0) {
	    ticket_num--;
	}
	pthread_mutex_unlock(&mutex);
    }
}

int main() {
    pthread_t t1,t2,t3;
    pthread_create(&t1, NULL, &sell_ticket, NULL);
    pthread_create(&t2, NULL, &sell_ticket, NULL);
    pthread_create(&t3, NULL, &sell_ticket, NULL);
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    pthread_join(t3, NULL);
    printf("ticket_num=%d\n", ticket_num);
    return 0;
}

```



[例子：](https://www.cnblogs.com/wsw-seu/p/8036218.html)

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <pthread.h>

pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
int gn;

void* thread(void *arg)
{
    printf("thread's ID is  %d\n",pthread_self());
    pthread_mutex_lock(&mutex);
    gn = 12;
    printf("Now gn = %d\n",gn);
    pthread_mutex_unlock(&mutex);
    return NULL;
}

int main()
{
    pthread_t id;
    printf("main thread's ID is %d\n",pthread_self());
    gn = 3;
    printf("In main func, gn = %d\n",gn);
    if (!pthread_create(&id, NULL, thread, NULL)) {
        printf("Create thread success!\n");
    } else {
        printf("Create thread failed!\n");
    }
    pthread_join(id, NULL);
    pthread_mutex_destroy(&mutex);
    return 0;
}
```



[例子：](https://www.cnblogs.com/eustoma/p/10054783.html)下面是一段测试代码，创建两个线程，分别访问全局变量gnum，并且修改它，打印出来.

```c
/* mutex.c */
#include <stdlib.h>
#include <stdio.h>
#include <pthread.h>
#include <errno.h>

/* 全局变量 */
int gnum = 0;
/* 互斥量 */
pthread_mutex_t mutex;

/* 声明线程运行服务程序. */
static void pthread_func_1(void);
static void pthread_func_2(void);

int main (void)
{
 /*线程的标识符*/
  pthread_t pt_1 = 0;
  pthread_t pt_2 = 0;
  int ret = 0;

  /* 互斥初始化. */
  pthread_mutex_init(&mutex, NULL);
  /*分别创建线程1、2*/
  ret = pthread_create(&pt_1,  //线程标识符指针
                       NULL,  //默认属性
                       (void*)pthread_func_1, //运行函数
                       NULL); //无参数
  if (ret != 0)
  {
     perror ("pthread_1_create");
  }

  ret = pthread_create(&pt_2, //线程标识符指针
                       NULL,  //默认属性
                       (void *)pthread_func_2, //运行函数
                       NULL); //无参数
  if (ret != 0)
  {
     perror ("pthread_2_create");
  }
  /*等待线程1、2的结束*/
  pthread_join(pt_1, NULL);
  pthread_join(pt_2, NULL);

  printf ("main programme exit!/n");
  return 0;
}

/*线程1的服务程序*/
static void pthread_func_1(void)
{
  int i = 0;

  for (i=0; i<3; i++) {
    printf ("This is pthread_1!/n");
    pthread_mutex_lock(&mutex); /* 获取互斥锁 */
    /* 注意，这里以防线程的抢占，以造成一个线程在另一个线程sleep时多次访问互斥资源，所以sleep要在得到互斥锁后调用. */
    sleep (1);
    /*临界资源*/
    gnum++;
    printf ("Thread_1 add one to num:%d/n", gnum);
    pthread_mutex_unlock(&mutex); /* 释放互斥锁. */
  }

  pthread_exit(NULL);
}

/*线程2的服务程序*/
static void pthread_func_2(void)
{
  int i = 0;

  for (i=0; i<5; i++)  {
    printf ("This is pthread_2!/n");
    pthread_mutex_lock(&mutex); /* 获取互斥锁. */
    /* 注意，这里以防线程的抢占，以造成一个线程在另一个线程sleep时多次访问互斥资源，所以sleep要在得到互斥锁后调用. */
    sleep(1);
    /* 临界资源. */
    gnum++;
    printf ("Thread_2 add one to num:%d/n",gnum);
    pthread_mutex_unlock(&mutex); /* 释放互斥锁. */
  }

  pthread_exit (NULL);
}
```







#   条件变量（cond）



条件变量可以让调用线程在满足特定条件的情况下运行，不满足条件时阻塞等待被唤醒，必须与互斥锁搭配使用。

条件变量常用于生产者与消费者模型。

相关方法：

```c
pthread_cond_t cond=PTHREAD_COND_INITIALIZER; // 创建条件变量，一个互斥锁可以对应多个条件变量

int pthread_cond_wait (pthread_cond_t* cond,pthread_mutex_t* mutex); // 阻塞等待条件满足，同时释放互斥锁mutex

int pthread_cond_timedwait (pthread_cond_t* cond, pthread_mutex_t* mutex, const struct timespec* abstime); // 带超时的阻塞等待条件满足，同时释放互斥锁mutex

// 从条件变量cond中唤出一个线程，令其重新获得原先的互斥锁
// 被唤出的线程此刻将从pthread_cond_wait函数中返回，但如果该线程无法获得原先的锁，则会继续阻塞在加锁上。
int pthread_cond_signal (pthread_cond_t* cond);

// 从条件变量cond中唤出所有线程
int pthread_cond_broadcast (pthread_cond_t* cond);

```





例子：

```c
#include<stdio.h>
#include<pthread.h>

int max_buffer=10;
int count=0;

pthread_mutex_t mutex=PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t notempty=PTHREAD_COND_INITIALIZER;
pthread_cond_t notfull=PTHREAD_COND_INITIALIZER;

void *produce(void *args) {
    while(1) {
        pthread_mutex_lock(&mutex);
        while(count == max_buffer) {
            printf("buffer is full, wait...\n");
            pthread_cond_wait(&notfull, &mutex);
        }
        printf("produce ...\n");
        count++;
        sleep(1);
        pthread_cond_signal(&notempty);
        pthread_mutex_unlock(&mutex);
    }

}

void *consumer(void *args) {
    while(1) {
        pthread_mutex_lock(&mutex);
        while(count == 0) {
            printf("buffer is empty, wait...\n");
            pthread_cond_wait(&notempty, &mutex);
        }
        printf("consumer ...\n");
        count--;
        sleep(1);
        pthread_cond_signal(&notfull);
        pthread_mutex_unlock(&mutex);
    }

}

int main() {
    pthread_t t1,t2,t3,t4;
    pthread_create(&t1, NULL, &produce, NULL);
    pthread_create(&t2, NULL, &produce, NULL);

    pthread_create(&t3, NULL, &consumer, NULL);
    pthread_create(&t4, NULL, &consumer, NULL);

    pthread_join(t1, NULL);
    return 0;
}

```





条件变量给了线程以无竞争的方式等待特定条件发生。条件变量是和互斥量一起使用的，条件变量是由互斥量保护的。这么讲，大家可能不明白，这条件变量有什么用？干什么的？还是结合pthread_cond_wait()函数来分析一下吧！

单刀直入，我们需要分析的重点就是pthread_cond_wait()函数。而pthread_cond_timewait()只是比它多了个超时而已。

pthread_cond_wait()函数等待条件变量变为真的。它需要两个参数，第一个参数就是条件变量，而第二个参数mutex是保护条件变量的互斥量。也就是说这个函数在使用的时候需要配合pthread_mutex_lock()一起使用。即：

下面给出本文讲使用的的有关条件变量的函数。







#  读写锁



读写锁可以有三种状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。读写锁也叫做共享-独占锁，当读写锁以读模式锁住时，它是以共享模式锁住的，当它以写模式锁住时，它是以独占模式锁住的，读读共享，读写互斥。

相关方法：

```c
// 创建读写锁
pthread_rwlock_t rwlock=PTHREAD_RWLOCK_INITIALIZER;

int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock); // 加读锁，阻塞
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock); // 加写锁，阻塞
int pthread_rwlock_unlock(pthread_rwlock_t *rwlock); // 释放读锁或者写锁

int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock); // 尝试加读锁，非阻塞
int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock); // 尝试加写锁，非阻塞

```

例子：

```c
#include <stdio.h>
#include <pthread.h>

pthread_rwlock_t rwlock=PTHREAD_RWLOCK_INITIALIZER;

void *read(void *arg) {
    while(1) {
        pthread_rwlock_rdlock(&rwlock);
        rintf("read message.\n");
        sleep(1);
        pthread_rwlock_unlock(&rwlock);
        sleep(1);
    }
}
void *write(void *arg) {
    while(1) {
        pthread_rwlock_wrlock(&rwlock);
        printf("write message.\n");
        sleep(1);
        pthread_rwlock_unlock(&rwlock);
        sleep(1);
    }
}

int main(int argc,char *argv[]) {
    pthread_t t1,t2,t3;
    pthread_create(&t1, NULL, &read, NULL);
    pthread_create(&t2, NULL, &read, NULL);

    pthread_create(&t3, NULL, &write, NULL);

    pthread_join(t1, NULL);
    return 0;
}

```





# 信号量(sem)

信号量是一个计数器，用于控制访问有限共享资源的线程数。

相关方法：

```c
// 创建信号量
// pshared：一般取0，表示调用进程的信号量。非0表示该信号量可以共享内存的方式，为多个进程所共享(Linux暂不支持)。
// value：信号量的初始值，可以并发访问的线程数。
int sem_init (sem_t* sem, int pshared, unsigned int value);

int sem_wait (sem_t* sem); // 信号量减1，信号量为0时就会阻塞

int sem_trywait (sem_t* sem); // 信号量减1，信号量为0时返回-1，不阻塞

int sem_timedwait (sem_t* sem, const struct timespec* abs_timeout); // 信号量减1，信号量为0时阻塞，直到abs_timeout超时返回-1

int sem_post (sem_t* sem); // 信号量加1

```

例子：

```c
#include<stdio.h>
#include<pthread.h>
#include <semaphore.h>

int ticket_num=10000000;

sem_t sem;

void *sell_ticket(void *arg) {
    while(ticket_num>0) {
	sem_wait(&sem);
	if(ticket_num>0) {
	    ticket_num--;
	}
	sem_post(&sem);
    }
}

int main() {
    sem_init(&sem, 0, 1); // value=1表示最多1个线程同时访问共享资源，与互斥量等价
    pthread_t t1,t2,t3;
    pthread_create(&t1, NULL, &sell_ticket, NULL);
    pthread_create(&t2, NULL, &sell_ticket, NULL);
    pthread_create(&t3, NULL, &sell_ticket, NULL);
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    pthread_join(t3, NULL);
    printf("ticket_num=%d\n", ticket_num);
    return 0;
}

```





sem_init()

sem_open()



sem_wait()



sem_close()(



sem_destory()





#  屏障（barrier)

屏障（barrier)是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后所有线程都从该点继续执行。pthread_join函数就是一种屏障，允许一个线程等待，直到另一个线程退出。但屏障对象的概念更广，允许任意数量的线程等待，直到所有的线程完成处理工作，而线程不需要退出，当所有的线程达到屏障后可以接着工作。

相关方法：

```c
// 创建屏障
int pthread_barrier_init(pthread_barrier_t *barrier,const pthread_barrrierattr_t *attr,unsigned int count)

// 阻塞等待，直到所有线程都到达
int pthread_barrier_wait(pthread_barrier_t *barrier)

```



例子：

```c
#include <stdio.h>
#include <pthread.h>

pthread_barrier_t barrier;

void *go(void *arg){
    sleep (rand () % 10);
    printf("%lu is arrived.\n", pthread_self());
    pthread_barrier_wait(&barrier);
    printf("%lu go shopping...\n", pthread_self());
}

int main() {
    pthread_barrier_init(&barrier, NULL, 3);

    pthread_t t1,t2,t3;
    pthread_create(&t1, NULL, &go, NULL);
    pthread_create(&t2, NULL, &go, NULL);
    pthread_create(&t3, NULL, &go, NULL);

    pthread_join(t1, NULL);
    return 0;
}

```



