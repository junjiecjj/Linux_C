

# 函数与内存

## [申请内存时底层发生了什么？](https://mp.weixin.qq.com/s/DN-ckM1YrPMeicN7P9FvXg)

识不到的东西却无比重要，申请过这么多内存，**你知道申请内存时底层都发生什么了吗**？

我们就从神话故事开始吧。



> **三界**

中国古代的神话故事通常有“三界”之说，一般指的是天、地、人三界，天界是神仙所在的地方，凡人无法企及；人界说的是就是人间；地界说的是阎罗王所在的地方，孙悟空上天入地无所不能就是说可以在这三界自由出入。

有的同学可能会问，这和计算机有什么关系呢？

原来，我们的代码也是分三六九等的，程序运行起来后也是有“三界”之说的，程序运行起来的“三界”就是这样的：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUzGCKPsIQwtHU6atfP23MvxZmrbIjjntNGxAZ3IXOfmBMibnzLDJghkA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

x86 CPU提供了“四界”：0,1,2,3，**这几个数字其实就是指CPU的几种工作状态**，数字越小表示CPU的特权越大，0号状态下CPU特权最大，可以执行任何指令，数字越大表示CPU特权越小，3号状态下CPU特权最小，不能执行一些特权指令。

一般情况下系统只使用0和3，因此确切的说是“两界”，这两界可不是说天、地，这两界指的是“用户态(3)”以及“内核态(0)”，接下来我们看看什么是内核态、什么是用户态。



> **内核态**

什么是内核态？当CPU执行操作系统代码时就处于内核态，**在内核态下CPU可以执行任何机器指令、访问所有地址空间、不受限制的访问任何硬件**，可以简单的认为内核态就是“天界”，在这里的代码(操作系统代码)无所不能。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUBWWX8bkrGllWY1YGO0z0D0bHjiaicMQ3icO8RZbvl58f7bQUFpg3YMblA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



> **用户态**

什么是用户态？当CPU执行我们写的“普通”代码(非操作系统、驱动程序员)时就处于用户态，粗糙的划分方法就是除了操作系统之外的代码，就像我们写的HelloWorld程序。

用户态就好比“人界”，在用户态我们的代码处处受限，不能直接访问硬件、不能访问特定地址空间，否则神仙(操作系统)直接将你kill掉，这就是著名的Segmentation fault、不能执行特权指令，等等。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUkKk9tz3fgSF9ejzVWnxicNrRcviaZYjtqWicwJ3GuMpSBM2oWniacxlueQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

关于这一部分的详细讲解，请参见《[深入理解操作系统](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NTYyOTQ4OQ==&action=getalbum&album_id=1433368223499796481#wechat_redirect)》系列文章。



> **跨界**

孙悟空神通广大，一个跟斗就能从人间跑到天上去骂玉帝老儿，程序员就没有这个本领了。普通程序永远也去不了内核态，只能以通信的方式从用户态往内核态传递信息。

操作系统为普通程序员留了一些特定的暗号，这些暗号就和普通函数一样，程序员通过调用这些暗号就能向操作系统请求服务了，这些像普通函数一样的暗号就被称为[**系统调用**](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247483880&idx=1&sn=26ab417ffdd46b2956e5dc07516477af&chksm=fcb986b6cbce0fa0e0959341ec9c7a0c2db0acd9f5a1250e5cbe33306da2f10f1f3cd08152aa&scene=21#wechat_redirect)，System Call，通过系统调用我们可以让操作系统代替我们完成一些事情，像打开文件、网络通信等等。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPU6nDiazC6U7A9gLAwKOYTscricaKKicESIbiaAnXia3tqCs0upAjsictJXpiaw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

你可能有些疑惑，什么，还有系统调用这种东西，为什么我没调用过也可以打开文件、进行网络通信？



> **标准库**

虽然我们可以通过系统让操作系统替我们完成一些特定任务，但这些系统调用都是和操作系统强相关的，Linux和Windows的系统调用就完全不同。

如果你直接使用系统调用的话，那么Linux版本的程序就没有办法在Windows上运行，因此我们需要某种标准，该标准对程序员屏蔽底层差异，这样程序员写的程序就无需修改的在不同操作系统上运行了。

在C语言中，这就是所谓的**标准库**。

注意，标准库代码也是运行在用户态的，并不是神仙(操作系统)，一般来说，我们调用标准库去打开文件、网络通信等等，标准库再根据操作系统选择对应的系统调用。

从分层的角度看，我们的程序一般都是这样的汉堡包类型：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPU6CicgEJETyCvCkQiaF9yZ6wickG6bmKqbOv5Rq9CXlGoExibic9Aedcniaiag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

最上层是应用程序，应用程序一般只和标准库打交道(当然，我们也可以绕过标准库)，标准库通过系统调用和操作系统交互，操作系统管理底层硬件。

**这就是为什么在C语言下同样的open函数既能在Linux下打开文件也能在Windows下打开文件的原因**。

说了这么多，这和malloc又有什么关系呢？



> **主角登场**

原来，我们分配内存时使用的malloc函数其实不是实现在操作系统里的，而是在标准库中实现的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUCaWAXfdCrP8Q9LqJQTJtxplt150VY6eKvQR2MO3iaUefbcQPmMS7Bjw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

现在我们知道了，malloc是标准库的一部分，当我们调用malloc时实际上是标准库在为我们申请内存。

这里值得注意的是，我们平时在C语言中使用malloc只是内存分配器的一种，实际上有很多内存分配器，像tcmalloc，jemalloc等等，它们都有各自适用的场景，对于高性能程序来说使用满足特定要求的内存分配器是至关重要的。

那么接下来的问题就是malloc又是怎么工作的呢？



> **malloc是如何工作的**

实际上你可以把malloc的工作理解为去停车场找停车位，停车场就是一片malloc持有的内存，可用的停车位就是可供malloc支配的空闲内存，停在停车场占用的车位就是已经分配出去的内存，特殊点在于停在该停车场的车宽度大小不一，malloc需要回答这样一个问题：当有一辆车来到停车场后该停到哪里？

通过上面的类比你应该能大体理解工作原理了，具体分析详见《[自己动手实现一个malloc内存分配器](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247485171&idx=1&sn=d93f2f5e9d61b00515c043776d2f7330&chksm=fcb981adcbce08bb39d120d7bfd097308371fb4b4e4369ba9502ae4e4243028b450bd0fe3110&scene=21#wechat_redirect)》。

但是，请注意，**上面这****篇文章并不是故事的全部**，在这篇文章中有一个问题我们故意忽略了，这个问题就是**如果内存分配器中的空闲内存块不够用了该怎么办呢**？

在上面这篇文章中我们总是假定自己实现的malloc总能找到一块空闲内存，但实际上并不是这样的。



> **内存不够该怎么办？**

让我们再来看一下程序在内存中是什么样的：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPU7M3vQH0jVRDWx2bZPgic6ATaHiapb3iaK7bh4YicEQGhNXvavQToeVHb6w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

我们已经知道了，malloc管理的是堆区，注意，在堆区和栈区之间有一片空白区域，这片空白区域的目的是什么呢？

原来，栈区其实是可以增长的，随着调用深度的增加，相应的栈区占用的内存也会增加，关于栈区这一主题，你可以参考《[函数运行时在内存中是什么样子](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247484963&idx=1&sn=542d3bec57c6a9dfc17c83005fd2c030&chksm=fcb9817dcbce086b10cb44cad7c9777b0088fb8d9d6baf71ae36a9b03e1f8ef5bec62b79d6f7&scene=21#wechat_redirect)》这篇文章。

栈区的增长就需要占用原来的空白区域。

相应的，堆区也可以增长：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUibCxiaHf5fONfge0DMCHZgP3XXncRoV2Dwhiarrw3uJERoZEgTJicdRkow/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

堆区增长后占用的内存就会变多，这就解决了内存分配器空闲内存不足的问题，那么很自然的，malloc该怎样让堆区增长呢？

原来malloc内存不足时要向操作系统申请内存，**操作系统才是真大佬**，malloc不过是小弟，对每个进程，操作系统(类Unix系统)都维护了一个叫做brk的变量，brk发音break，这个brk指向了堆区的顶部。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUBaN7diaLZy5Z7kAkYHvU8pV4BcaRFMV8NmcbNRgrW040KEWVDKtolbw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

将brk上移后堆区增大，那么我们该怎么样让堆区增大呢？

这就涉及到我们刚提到的系统调用了。



> **向操作系统申请内存**

操作系统专门提供了一个叫做brk的系统调用，还记得刚提到堆的顶部吧，这个brk()系统调用就是用来增加或者减小堆区的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUuibpNKII4KyVk4FDs8I5mQglzJDanibSZfbibxn9cbJ3gY7zG2vs9rD9A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

实际上不只brk系统调用，sbr、mmap系统调用也可以实现同样的目的，mmap也更为灵活，但该函数并不是本文重点，就不在这里详细讨论了。

现在我们知道了，如果malloc自己维护的内存空间不足将通过brk系统调用向操作系统申请内存。这样malloc就可以把这些从操作系统申请到的内存当做新的空闲内存块分配出去。



> **看起来已经讲完的故事**

现在我就可以简单总结一下了，当我们申请内存时，经历这样几个步骤：

1. 程序调用malloc申请内存，注意malloc实现在标准库中
2. malloc开始搜索空闲内存块，如果能找到一块大小合适的就分配出去，前两个步骤都是发生在用户态
3. 如果malloc没有找到空闲内存块那么就像操作系统发出请求来增大堆区，这是通过系统调用brk(sbrk、mmap也可以)实现的，注意，brk是操作系统的一部分，因此当brk开始执行时，此时就进入内核态了。brk增大进程的堆区后返回，malloc的空闲内存块增加，此时malloc又一次能找到合适的空闲内存块然后分配出去。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUO3f3ztpm8WRXfblEAvHOhydv8Zr1o58usmryw9GrhbI6YeIT5MQz5g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

故事就到这里了吗？



> **冰山之下**

实际上到目前为止，我们接触到的仅仅是冰山一角。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUOXGKA1bG5ojicgS3cEI0MMVp54qOH46KQHb3BgApHXpQmlrKwjYKnWg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

我们看到的冰山是这样的：我们向malloc申请内存，malloc内存不够时向操作系统申请内存，之后malloc找到一块空闲内存返回给调用者。

但是，你知道吗，**上述过程根本就没有涉及到哪怕一丁点物理内存**！！！

我们确实向malloc申请到内存了，malloc不够也确实从操作系统申请到内存了，但这些内存都不是真的物理内存，**NOT REAL**。

实际上，进程看到的内存都是假的，是操作系统给进程的一个幻象，这个幻象就是由著名的**虚拟内存**系统来维护的，我们经常说的这张图就是进程的虚拟内存。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPU7M3vQH0jVRDWx2bZPgic6ATaHiapb3iaK7bh4YicEQGhNXvavQToeVHb6w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

所谓虚拟内存就是假的、不是真正的物理内存，虚拟内存是给进程用的，操作系统维护了虚拟内存到物理内存的映射，当malloc返回后，程序员申请到的内存就是虚拟内存。

注意，**此时操作系统根本就没有真正的分配物理内存，程序员从malloc拿到的内存目前还只是一张空头支票**。

那么这张空头支票什么时候才能兑现呢？也就是什么时候操作系统才会真正的分配物理内存呢？

答案是当我们真正使用这段内存时，当我们真正使用这段内存时，这时会产生一个缺页错误，操作系统捕捉到该错误后开始真正的分配物理内存，操作系统处理完该错误后我们的程序才能真正的读写这块内存。

这里只是简略的提到了虚拟内存，实际上虚拟内存是当前操作系统内部极其重要的一部分，关于虚拟内存的工作原理将在《[深入理解操作系统](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzU2NTYyOTQ4OQ==&action=getalbum&album_id=1433368223499796481#wechat_redirect)》系列文章中详细讨论。



> **完整的故事**

现在，这个故事就可以完整讲出来了，当我们调用malloc申请内存时：

1. malloc开始搜索空闲内存块，如果能找到一块大小合适的就分配出去
2. 如果malloc找不到一块合适的空闲内存，那么调用brk等系统调用扩大堆区从而获得更多的空闲内存
3. malloc调用brk后开始转入内核态，此时操作系统中的虚拟内存系统开始工作，扩大进程的堆区，注意额外扩大的这一部分内存仅仅是虚拟内存，操作系统并没有为此分配真正的物理内存
4. brk执行结束后返回到malloc，从内核态切换到用户态，malloc找到一块合适的空闲内存后返回
5. 程序员拿到新申请的内存，程序继续
6. 当有代码读写新申请的内存时系统内部出现缺页中断，此时再次由用户态切换到内核态，操作系统此时真正的分配物理内存，之后再次由内核态切换回用户态，程序继续。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0PwrdKmE9AkGwaqia6icELPUSVyLUeFf3bAv8kJ6IBKpERibQZqqiaJSGx6jdKllImYIC9NnlpY3ic2Ww/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

以上就是一次内存申请的完整过程，可以看到一次内存申请过程是非常复杂的。



> **总结**

怎么样，程序员申请内存使用的malloc虽然表面看上去非常简单，简单到就一行代码，但这行代码背后是非常复杂的。

有的同学可能会问，为什么我们要理解这背后的原理呢？理解了原理后我才能知道内存申请的复杂性，对于高性能程序来讲频繁的调用malloc对系统性能是有影响的，那么很自然的一个问题就是我们能否避免malloc？

##   [函数运行时在内存中是什么样子？](https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485714&idx=1&sn=1a315fe4da87fde2758fc9dd5366ba01&source=41#wechat_redirect)



在开始本篇的内容前，我们先来思考几个问题。

1. 我们先来看一段简单的代码：

   ```c
   void func(int a) {
     if (a > 100000000) return;

     int arr[100] = {0};
     func(a + 1);
   }
   ```

2. 我们在上一篇文章《[**高性能高并发服务器是如何实现的**](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247484933&idx=1&sn=c4112a54f5751f38e841baf3e3cc35bd&chksm=fcb9815bcbce084de2823467d3ba9d3e835663a6bb69df1fc7f71677aef099584f93b0e01809&scene=21#wechat_redirect)》中提到了一项关键技术——协程，你知道协程的本质是什么吗？有的同学可能会说是用户态线程，那么什么是用户态线程，这是怎么实现的？

3. 函数运行起来后在内存中是什么样子？

这几个问题看似没什么关联，但这背后都指向一样东西，这就是所谓的函数**运行时栈**，**run time stack**。

接下来我们就好好看看到底什么是函数运行时栈，为什么彻底理解函数运行时栈对程序员来说非常重要。

> **从进程、线程到函数调用**

汽车在高速上行驶时有很多信息，像速度、位置等等，通过这些信息我们可以直观的感受汽车的运行时状态。

里等等，通过这些信息我们可以直观的感受系统中程序运行的状态。

其中，我们创造了进程、线程这样的概念来记录有哪些程序正在运行，关于进程和线程的概念请参见《[**看完这篇还不懂进程、线程与线程池你来打我**](https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485705&idx=1&sn=1845875575601b23ed5cea0579c1f77e&source=41#wechat_redirect)》。

**进程和线程的运行体现在函数执行上**，函数的执行除了函数内部执行的顺序执行还有子函数调用的控制转移以及子函数执行完毕的返回。其中函数内部的顺序执行乏善可陈，重点是函数的调用。

因此接下来我们的视角将从宏观的进程和线程拉近到微观下的函数调用，重点来讨论一下函数调用是怎样实现的。



>  **函数执行的活动轨迹：栈**

玩过游戏的同学应该知道，有时你为了完成一项主线任务不得不去打一些支线的任务，支线任务中可能还有支线任务，当一个支线任务完成后退回到前一个支线任务，这是什么意思呢，举个例子你就明白了。

假设主线任务西天取经A依赖支线任务收服孙悟空B和收服猪八戒C，也就是说收服孙悟空B和收服猪八戒C完成后才能继续主线任务西天取经A；

支线任务收服孙悟空B依赖任务拿到紧箍咒D，只有当任务D完成后才能回到任务B；

整个任务的依赖关系如图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UM6nPtWzlRuA1EU8Inc4cp30xQCyiaGTAvatAOSrdKYM9UnrkChzVHKibQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

现在我们来模拟一下任务完成过程。

首先我们来到任务A，执行主线任务：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMWEicBfDADgsdzibPLyJoFiaGANL5OBYmMGoMmOys7ic209SbiazzSXguhlA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

执行任务A的过程中我们发现任务A依赖任务B，这时我们暂停任务A去执行任务B：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMlaT1C1nZ4Nib1AlhibdOTia1lrYSGb054xd20IFjWKCdXcX0HwicTicdLOQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

执行任务B的时候，我们又发现依赖任务D：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UM2WGO1bReDXjbu4ts90MNoFY9s5pgUThvA7EATPjianYdIliaBlQGXaoQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

执行任务D的时候我们发现该任务不再依赖任何其它任务，因此C完成后我们可以会退到前一个任务，也就是B：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMlaT1C1nZ4Nib1AlhibdOTia1lrYSGb054xd20IFjWKCdXcX0HwicTicdLOQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

任务B除了依赖任务C外不再依赖其它任务，这样任务B完成后就可以回到任务A：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMWEicBfDADgsdzibPLyJoFiaGANL5OBYmMGoMmOys7ic209SbiazzSXguhlA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

现在我们回到了主线任务A，依赖的任务B执行完成，接下来是任务C：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMPZ0rRnEdnBsDPD4RTY08To0AicbHRoK7WhzFvu6XvzPjMo0O0JKZl7Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

和任务D一样，C不依赖任何其它其它任务，任务C完成后就可以再次回到任务A，再之后任务A执行完毕，整个任务执行完成。

让我们来看一下整个任务的活动轨迹：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMibA8lEicYT8Lor9AylgiaHXwaSC2wPpOZL0Tib4o1vk6ib9MeMTn0wzdchg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

仔细观察，实际上你会发现这是一个First In Last Out 的顺序，天然适用于栈这种数据结构来处理。

再仔细看一下栈顶的轨迹，也就是A、B、D、B、A、C、A，**实际上你会发现这里的轨迹就是任务依赖树的遍历过程**，是不是很神奇，这也是为什么树这种数据结构的遍历除了可以用递归也可以用栈来实现的原因。



>  **A Box**

函数调用也是同样的道理，你把上面的ABCD换成函数ABCD，本质不变。

因此，现在我们知道了，使用栈这种结构就可以用来保存函数调用信息。

和游戏中的每个任务一样，当函数在运行时每个函数也要有自己的一个“小盒子”，**这个小盒子中保存了函数运行时的各种信息**，这些小盒子通过栈这种结构组织起来，这个小盒子就被称为栈帧，stack frames，也有的称之为call stack，不管用什么命名方式，总之，就是这里所说的小盒子，这个小盒子就是函数运行起来后占用的内存，**这些小盒子构成了我们通常所说的栈区**。关于栈区详细的讲解你可以参考《[**深入理解操作系统：程序员应如何理解内存**](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247483839&idx=1&sn=20276b1966b76530890e9f09c6f41892&chksm=fcb986e1cbce0ff73c50f1a3f943bf182d8db666b27b4e55d20bd7cbbdea3fadbfbcb7c68f26&scene=21#wechat_redirect)》一文。

那么函数调用时都有哪些信息呢？



>  **控制转移**

我们知道当函数A调用函数B的时候，控制从A转移到了B，所谓控制其实就是指CPU执行属于哪个函数的机器指令，CPU从开始执行属于函数A的指令切换到执行属于函数B的指令，我们就说控制从函数A转移到了函数B。

控制从函数A转移到函数B，那么我们需要有这样两个信息：

- 我从哪里来 (返回)
- 要到去哪里 (跳转)

是不是很简单，就好比你出去旅游，你需要知道去哪里，还需要记住回家的路。

函数调用也是同样的道理。

当函数A调用函数B时，我们只要知道：

- 函数A对于的机器指令执行到了哪里 (我从哪里来，返回)
- 函数B第一条机器指令所在的地址 (要到哪里去，跳转)

有这两条信息就足以让CPU开始执行函数B对应的机器指令，当函数B执行完毕后跳转回函数A。

那么这些信息是怎么获取并保持的呢？

现在我们就可以打开这个小盒子，看看是怎么使用的了。

假设函数A调用函数B，如图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMVjgxLV2L5Nn0WhGZAhge7RzdD01u5CzR7RpbictDlDrb3719cLbKfeA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

当前，CPU执行函数A的机器指令，该指令的地址为0x400564，接下来CPU将执行下一条机器指令也就是:

-

```c
call 0x400540
```



这条机器指令是什么意思呢？

这条机器指令对应的就是我们在代码中所写的函数调用，注意call后有一条机器指令地址，注意观察上图你会看到，**该地址就是函数B的第一条机器指令**，从这条机器指令后CPU将跳转到函数B。

现在我们已经解决了控制跳转的“要到哪里去”问题，当函数B执行完毕后怎么跳转回来呢？

原来，call指令除了给出跳转地址之外还有这样一个作用，也就是**把call指令的下一条指令的地址，也就是0x40056a push到函数A的栈帧中**，如图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMQsNg63AfUVOusvQkTa19wTBdmIK2l2h2AggIiceYQ1zf8pTPlomRSrQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1 =100x80)

现在，函数A的小盒子变大了一些，因为装入了返回地址：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMLHu7EPtcboFPDiciaZ2ZJFtGjdDRIYY5icialsYTjAnu2uUMI396iaNRQ6Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

现在CPU开始执行函数B对应的机器指令，注意观察，函数B也有一个属于自己的小盒子(栈帧)，可以往里面扔一些必要的信息。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMEFHVVgibvBicAtmibj1s06Vr5M7ibWk4rJoxcoiclYeFXcfXsXibQNkf1E4w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

如果函数B中又调用了其它函数呢？

道理和函数A调用函数B是一样的。

让我们来看一下函数B最后一条机器指令ret，这条机器指令的作用是告诉CPU跳转到函数A保存在栈帧上的返回地址，这样当函数B执行完毕后就可以跳转到函数A继续执行了。

至此，我们解决了控制转移中“我从哪里来”的问题。



>  **传递参数与获取返回值**

函数调用与返回使得我们可以编写函数，进行函数调用。但调用函数除了提供函数名称之外还需要传递参数以及获取返回值，那么这又是怎样实现的呢？

在x86-64中，多数情况下参数的传递与获取返回值是通过**寄存器**来实现的。

假设函数A调用了函数B，函数A将一些参数写入相应的寄存器，当CPU执行函数B时就可以从这些寄存器中获取参数了。

同样的，函数B也可以将返回值写入寄存器，当函数B执行结束后函数A从该寄存器中就可以读取到返回值了。

我们知道寄存器的数量是有限的，当传递的参数个数多于寄存器的数量该怎么办呢？

这时那个属于函数的小盒子也就是栈帧又能发挥作用了。

原来，当参数个数多于寄存器数量时剩下的参数直接放到栈帧中，这样被调函数就可以**从前一个函数的栈帧中获取到参数了**。

现在栈帧的样子又可以进一步丰富了，如图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMzLPnnNzHXLsYF3VAXoAsBCpibA17YRdaXiamLnfibpv0vURiaIQicLCTZdg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

从图中我们可以看到，调用函数B时有部分参数放到了函数A的栈帧中，同时函数A栈帧的顶部依然保存的是返回地址。



> **局部变量**

我们知道在函数内部定义的变量被称为局部变量，这些变量在函数运行时被放在了哪里呢？

原来，这些变量同样可以放在寄存器中，但是当局部变量的数量超过寄存器的时候这些变量就必须放到栈帧中了。

因此，我们的栈帧内容又一步丰富了。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMM3Q3LQdcQLJdtGktOKxoxqZeRxAgMsqFHuthohdnBBtN2hWDmIicL9Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

细心的同学可能会有这样的疑问，我们知道寄存器是共享资源可以被所有函数使用，既然可以将函数A的局部变量写入寄存器，那么当函数A调用函数B时，函数B的局部变量也可以写到寄存器，这样的话当函数B执行完毕回到函数A时寄存器的值已经被函数B修改过了，这样会有问题吧。

这样的确会有问题，因此我们在向寄存器中写入局部变量之前，**一定要先将寄存器中开始的值保存起来**，当寄存器使用完毕后再恢复原值就可以了。

那么我们要将寄存器中的原始值保存在哪里呢？

有的同学可能已经猜到了，没错，依然是函数的栈帧中。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMib8974tib4sQXTWY9kywBtvHjFxTanphsQsUb6IprbevNBTGJuySplYQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

最终，我们的小盒子就变成了如图所示的样子，当寄存器使用完毕后根据栈帧中保存的初始值恢复其内容就可以了。

现在你应该知道函数在运行时到底是什么样子了吧，以上就是问题3的答案。



>  **Big Picture**

需要再次强调的一点就是，上述讨论的栈帧就位于我们常说的栈区。

栈区，属于进程地址空间的一部分，如图所示，我们将栈区放大就是图左边的样子。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya0WkCbTt37ejcAKNVsIu7UMkbNXU3lnWgRWhJMmtkFnTFxvicAXCuQTAibfGMkM0h57bdOe3E9YzQ9A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1 =80x80)

关于栈区详细的讲解你可以参考《[**深入理解操作系统：程序员应如何理解内存**](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247483829&idx=1&sn=b9c32f56e95bdc229315e2b5ffd365cd&chksm=fcb986ebcbce0ffdc6c087775b895f6a0c0b83c72a91ee5614e253bea005509de8abfab6fc0e&scene=21#wechat_redirect)》这篇。

最后，让我们回到文章开始的这段简单代码：

```c
void func(int a) {
    if (a > 100000000) return;

    int arr[100] = {0};
    func(a + 1);
}

void main(){
    func(0);
}
```



想一想这段代码会有什么问题？

原来，**栈区是有大小限制的**，当超过限制后就会出现著名的**栈溢出**问题，显然上述代码会导致这一问题的出现。

因此：

1. 不要创建过大的局部变量
2. 函数栈帧，也就是调用层次不能太多



**总结**

本章我们从几个看似没什么关联的问题出发，详细讲解了函数运行时栈是怎么一回事，为什么我们不能创建过多的局部变量。细心的同学会发现第2个问题我们没有解答，这个问题的讲解放到下一篇，也就是协程中讲解。





##   [线程间共享了哪些进程资源？](https://mp.weixin.qq.com/s/5Xq-uzbjCExWfws-czVYGQ)

进程和线程这两个话题是程序员绕不开的，操作系统提供的这两个抽象概念实在是太重要了。

关于进程和线程有一个**极其经典**的问题，那就是进程和线程的区别是什么？相信很多同学对答案似懂非懂。



>  **记住了不一定真懂**

关于这个问题有的同学可能已经“背得”滚瓜烂熟了：“进程是操作系统分配资源的单位，线程是调度的基本单位，**线程之间共享进程资源**”。

可是你真的理解了上面最后一句话吗？**到底线程之间共享了哪些进程资源，共享资源意味着什么？共享资源这种机制是如何实现的？**对此如果你没有答案的话，那么这意味着**你几乎很难写出能正确工作的多线程程序**，同时也意味着这篇文章就是为你准备的。



>  **逆向思考**

查理芒格经常说这样一句话：“反过来想，总是反过来想”，如果你对线程之间共享了哪些进程资源这个问题想不清楚的话那么也可以反过来思考，那就是**有哪些资源是线程私有的**。



> **线程私有资源**

线程运行的本质其实就是函数的执行，函数的执行总会有一个源头，这个源头就是所谓的入口函数，CPU从入口函数开始执行从而形成一个执行流，只不过我们人为的给执行流起一个名字，这个名字就叫线程。

既然线程运行的本质就是函数的执行，那么函数执行都有哪些信息呢？

在《[函数运行时在内存中是什么样子](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247484963&idx=1&sn=542d3bec57c6a9dfc17c83005fd2c030&chksm=fcb9817dcbce086b10cb44cad7c9777b0088fb8d9d6baf71ae36a9b03e1f8ef5bec62b79d6f7&scene=21#wechat_redirect)》这篇文章中我们说过，函数运行时的信息保存在栈帧中，栈帧中保存了函数的返回值、调用其它函数的参数、该函数使用的局部变量以及该函数使用的寄存器信息，如图所示，假设函数A调用函数B：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UNsZhzaGdjEAX7UrhQ9Zm6c0bC3tHYkahgiatFD7M8EYibTQDiaJx5LtJQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

此外，CPU执行指令的信息保存在一个叫做程序计数器的寄存器中，通过这个寄存器我们就知道接下来要执行哪一条指令。由于操作系统随时可以暂停线程的运行，因此我们保存以及恢复程序计数器中的值就能知道线程是从哪里暂停的以及该从哪里继续运行了。

由于线程运行的本质就是函数运行，函数运行时信息是保存在栈帧中的，因此每个线程都有自己独立的、私有的栈区。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UKECTocZz5RBaFsSicibSeKLsmkKcalTic01yJicf9Ig1JpVH7JEYicTaic8Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

同时函数运行时需要额外的寄存器来保存一些信息，像部分局部变量之类，这些寄存器也是线程私有的，**一个线程不可能访问到另一个线程的这类寄存器信息**。

从上面的讨论中我们知道，到目前为止，所属线程的栈区、程序计数器、栈指针以及函数运行使用的寄存器是线程私有的。

以上这些信息有一个统一的名字，就是**线程上下文**，thread context。

我们也说过操作系统调度线程需要随时中断线程的运行并且需要线程被暂停后可以继续运行，操作系统之所以能实现这一点，依靠的就是线程上下文信息。

现在你应该知道哪些是线程私有的了吧。

除此之外，剩下的都是线程间共享资源。

那么剩下的还有什么呢？还有图中的这些。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3U76WYIzjJfrQiciaicFja35ywtqpX8AduKvLrFBQPR51lepO5ZAvoYcDmw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这其实就是进程地址空间的样子，也就是说线程共享进程地址空间中除线程上下文信息中的所有内容，意思就是说线程可以**直接读取**这些内容。

接下来我们分别来看一下这些区域。

> **代码区**

进程地址空间中的代码区，这里保存的是什么呢？从名字中有的同学可能已经猜到了，没错，这里保存的就是我们写的代码，**更准确的是编译后的可执行机器指令**。

那么这些机器指令又是从哪里来的呢？答案是从可执行文件中加载到内存的，可执行程序中的代码区就是用来初始化进程地址空间中的代码区的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UtCicgiaqiaFU5qrMibe2XPcGXM9A7x3J69Cl2ncgf6afCn3iaYZCM2Y2FYw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

线程之间共享代码区，**这就意味着程序中的任何一个函数都可以放到线程中去执行，不存在某个函数只能被特定线程执行的情况**。

> **数据区**

进程地址空间中的数据区，这里存放的就是所谓的全局变量。

什么是全局变量？所谓全局变量就是那些你定义在函数之外的变量，在C语言中就像这样：



```c
char c; // 全局变量

void func() {

}
```

其中字符c就是全局变量，存放在进程地址空间中的数据区。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UEtibNTe7gC9X9ett0gA8EcDU9TTg93CqGQKoqc4e81RG9p8KDYZwgSQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在程序员运行期间，也就是run time，**数据区中的全局变量有且仅有一个实例，所有的线程都可以访问到该全局变量**。

值得注意的是，在C语言中还有一类特殊的“全局变量”，那就是用static关键词修饰过的变量，就像这样：

```c
void func(){
    static int a = 10;
}
```

注意到，**虽然变量a定义在函数内部，但变量a依然具有全局变量的特性**，也就是说变量a放在了进程地址空间的数据区域，**即使函数执行完后该变量依然存在**，而普通的局部变量随着函数调用结束和函数栈帧一起被回收掉了，但这里的变量a不会被回收，因为其被放到了数据区。

这样的变量对每个线程来说也是可见的，也就是说每个线程都可以访问到该变量。

> **堆区**

堆区是程序员比较熟悉的，我们在C/C++中用malloc或者new出来的数据就存放在这个区域，很显然，**只要知道变量的地址，也就是指针，任何一个线程都可以访问指针指向的数据**，因此堆区也是线程共享的属于进程的资源。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UY1zP3O4nm60RaE1iaRj5mHaWAPLDYyRVaxuflc3QFzSl8RYlh9eK5hg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> **栈区**

唉，等等！刚不是说栈区是线程私有资源吗，怎么这会儿又说起栈区了？

确实，从线程这个抽象的概念上来说，栈区是线程私有的，然而从实际的实现上看，**栈区属于线程私有这一规则并没有严格遵守**，这句话是什么意思？

通常来说，注意这里的用词是**通常**，通常来说栈区是线程私有，既然有通常就有不通常的时候。

不通常是因为不像进程地址空间之间的严格隔离，线程的栈区没有严格的隔离机制来保护，因此如果一个线程能拿到来自另一个线程栈帧上的指针，**那么该线程就可以改变另一个线程的栈区**，也就是说这些线程可以任意修改本属于另一个线程栈区中的变量。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3U6DwtO4rCcxRGcu5opoTjgUjHbE0SplTJ5lDPiaghICz30vwkuy89qZg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这从某种程度上给了程序员极大的便利，但同时，这也会导致极其难以排查到的bug。

试想一下你的程序运行的好好的，结果某个时刻突然出问题，定位到出问题代码行后根本就排查不到原因，你当然是排查不到问题原因的，因为你的程序本来就没有任何问题，是别人的问题导致你的函数栈帧数据被写坏从而产生bug，这样的问题通常很难排查到原因，需要对整体的项目代码非常熟悉，常用的一些debug工具这时可能已经没有多大作用了。

说了这么多，那么同学可能会问，一个线程是怎样修改本属于其它线程的数据呢？

接下来我们用一个代码示例讲解一下。

> **修改线程私有数据**

不要担心，以下代码足够简单：

```c
void thread(void* var) {
    int* p = (int*)var;
    *p = 2;
}

int main() {
    int a = 1;
    printf("a = %d\n",a);
    pthread_t tid;

    pthread_create(&tid, NULL, thread, (void*)&a);
    printf("now a = %d\n",a);
    return 0;
}
```

这段代码是什么意思呢？

首先我们在主线程的栈区定义了一个局部变量，也就是 int a= 1这行代码，现在我们已经知道了，局部变量a属于主线程私有数据，但是，接下来我们创建了另外一个线程。

在新创建的这个线程中，我们将变量a的地址以参数的形式传给了新创建的线程，然后我来看一下thread函数。

在新创建的线程中，我们获取到了变量a的指针，然后将其修改为了2，也就是这行代码，我们在新创建的线程中修改了本属于主线程的私有数据。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3U7JUibLhQnz6ULEKEPrgjHbhzAicXCiaPKboRRMvxNtIAkFPoSWtXYnicNg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

现在你应该看明白了吧，尽管栈区是线程的私有数据，但由于栈区没有添加任何保护机制，一个线程的栈区对其它线程是可以见的，也就是说我们可以修改属于任何一个线程的栈区。

但是在Ubuntu20中，不是上面的情况：

```c
****************************************************************
>> File Name: test.c
>> Author: 陈俊杰
>> Mail: 2716705056qq.com

>> Created Time: 2021年06月25日 星期五 19时15分58秒

>> 此程序的功能是：
************************************************************************/

#include <math.h>
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>

void thread(void *var) {
  int *p = (int *)var;
  printf("In child, a1 = %d\n", *p);
  *p = 2;
  printf("In child, a2 = %d\n", *p);
}

int main() {
  int a = 1;
  printf("a = %d\n", a);
  pthread_t tid;

  pthread_create(&tid, NULL, thread, (void *)&a);
  printf("now a = %d\n", a);
  pthread_join(tid, NULL);
  return 0;
}
```



```c
┌─[jack@unix] - [~/公共的/Linux_C/C_skills] - [2021-11-20 04:12:08]
└─[0] <git:(main 4337b5b✱✈) > gcc -o test -pthread test.c
test.c: In function ‘main’:
test.c:30:30: warning: passing argument 3 of ‘pthread_create’ from incompatible pointer type [-Wincompatible-pointer-types]
   30 |   pthread_create(&tid, NULL, thread, (void *)&a);
      |                              ^~~~~~
      |                              |
      |                              void (*)(void *)
In file included from test.c:12:
/usr/include/pthread.h:201:15: note: expected ‘void * (*)(void *)’ but argument is of type ‘void (*)(void *)’
  201 |       void *(*__start_routine) (void *),
      |       ~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~
┌─[jack@unix] - [~/公共的/Linux_C/C_skills] - [2021-11-20 04:12:10]
└─[0] <git:(main 4337b5b✱✈) > ./test                     
a = 1
now a = 1
In child, a1 = 1
In child, a2 = 2
┌─[jack@unix] - [~/公共的/Linux_C/C_skills] - [2021-11-20 04:12:11]
└─[0] <git:(main 4337b5b✱✈) > 

```



就像我们上文说得到的，这给程序员带来了极大便利的同时也带来了无尽的麻烦，试想上面这段代码，如果确实是项目需要那么这样写代码无可厚非，但如果上述新创建线程是因bug修改了属于其它线程的私有数据的话，那么产生问题就很难定位了，**因为bug可能距离问题暴露的这行代码已经很远了**，这样的问题通常难以排查。

> **动态链接库**

进程地址空间中除了以上讨论的这些实际上还有其它内容，还有什么呢？

这就要从可执行程序说起了。

什么是可执行程序呢？在Windows中就是我们熟悉的exe文件，在Linux世界中就是ELF文件，这些可以被操作系统直接运行的程序就是我们所说的可执行程序。

那么可执行程序是怎么来的呢？

有的同学可能会说，废话，不就是编译器生成的吗？

实际上这个答案只答对了一半。

假设我们的项目比较简单只有几个源码文件，编译器是怎么把这几个源代码文件转换为最终的一个可执行程序呢？

原来，编译器在将可执行程序翻译成机器指令后，接下来还有一个重要的步骤，这就是链接，链接完成后生成的才是可执行程序。

完成链接这一过程的就是链接器。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UwvIibKUkp3PExcAMtf1mugIcwGYR0BLzkT3RHxFCLMon1SHteXyM3Lg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

其中链接器可以有两种链接方式，这就是**静态链接**和**动态链接**。

静态链接的意思是说把所有的机器指令一股脑全部打包到可执行程序中，动态链接的意思是我们不把动态链接的部分打包到可执行程序，而是在可执行程序运行起来后去内存中找动态链接的那部分代码，这就是所谓的静态链接和动态链接。

动态链接一个显而易见的好处就是可执行程序的大小会很小，就像我们在Windows下看一个exe文件可能很小，**那么该exe很可能是动态链接的方式生成的**。

而动态链接的部分生成的库就是我们熟悉的动态链接库，在Windows下是以DLL结尾的文件，在Linux下是以so结尾的文件。

说了这么多，这和线程共享资源有什么关系呢？

原来如果一个程序是动态链接生成的，**那么其地址空间中有一部分包含的就是动态链接库**，否则程序就运行不起来了，这一部分的地址空间也是被所有线程所共享的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UJtnywWE8NIFjwsGwH6UV0EldGXnZjQ7p2fKVDAv3YKCicGP2MpBZsXg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

也就是说进程中的所有线程都可以使用动态链接库中的代码。

以上其实是关于链接这一主题的极简介绍，关于链接这一话题的详细讨论可以参考《[彻底理解链接器](http://mp.weixin.qq.com/s?__biz=MzU2NTYyOTQ4OQ==&mid=2247483677&idx=1&sn=09212e8e7ecf7d58bfee53fa04e74911&chksm=fcb98643cbce0f5503916804ffe95bdd30917c9829429bb7fca7191b84f8171409db83e6e28c&scene=21#wechat_redirect)》系列文章。

> **文件**

最后，如果程序在运行过程中打开了一些文件，那么进程地址空间中还保存有打开的文件信息，进程打开的文件也可以被所有的线程使用，这也属于线程间的共享资源。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UuuPsC5SXGR6nAEHyIsHiajCBxqicGP8bvTgwC1UBBTXFe4T0p6uYQPbg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> **One More Thing：TLS**

本文就这些了吗？

实际上关于线程私有数据还有一项没有详细讲解，因为再讲下去本篇就撑爆了，而且本篇已经讲解的部分足够用了，剩下的这一点仅仅作为补充，也就是选学部分，如果你对此不感兴趣的话完全可以跳过，没有问题![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya3FQ7uPTlj2CkqH7qdNaDEsEn3N6lhOGzAE3PSVvkoJHcxDF6bXFEKfwjqdN33YsLliaGLKC9oAgxw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)。

关于线程私有数据还有一项技术，那就是线程局部存储，Thread Local Storage，TLS。

这是什么意思呢？

其实从名字上也可以看出，所谓线程局部存储，是指存放在该区域中的变量有两个含义：

- 存放在该区域中的变量是全局变量，所有线程都可以访问
- 虽然看上去所有线程访问的都是同一个变量，但该全局变量独属于一个线程，一个线程对此变量的修改对其他线程不可见。

说了这么多还是没懂有没有？没关系，接下来看完这两段代码还不懂你来打我。

我们先来看第一段代码，不用担心，这段代码非常非常的简单：

```c
int a = 1; // 全局变量

void print_a() {
    cout<<a<<endl;
}

void run() {
    ++a;
    print_a();
}

void main() {
    thread t1(run);
    t1.join();

    thread t2(run);
    t2.join();
}
```

怎么样，这段代码足够简单吧，上述代码是用C++11写的，我来讲解下这段代码是什么意思。

- 首先我们创建了一个全局变量a，初始值为1
- 其次我们创建了两个线程，每个线程对变量a加1
- 线程的join函数表示该线程运行完毕后才继续运行接下来的代码

那么这段代码的运行起来会打印什么呢？

全局变量a的初始值为1，第一个线程加1后a变为2，因此会打印2；第二个线程再次加1后a变为3，因此会打印3，让我们来看一下运行结果：

```c
2
3
```

看来我们分析的没错，全局变量在两个线程分别加1后最终变为3。

接下来我们对变量a的定义稍作修改，其它代码不做改动：

```
__thread int a = 1; // 线程局部存储
```

我们看到全局变量a前面加了一个__thread关键词用来修饰，也就是说我们告诉编译器把变量a放在线程局部存储中，那这会对程序带来哪些改变呢？

简单运行一下就知道了：



```c
2
2
```

和你想的一样吗？有的同学可能会大吃一惊，为什么我们明明对变量a加了两次，但第二次运行为什么还是打印2而不是3呢？

想一想这是为什么。

原来，这就是线程局部存储的作用所在，线程t1对变量a的修改不会影响到线程t2，线程t1在将变量a加到1后变为2，但对于线程t2来说此时变量a依然是1，因此加1后依然是2。

因此，**线程局部存储可以让你使用一个独属于线程的全局变量**。也就是说，虽然该变量可以被所有线程访问，但该变量在每个线程中都有一个副本，一个线程对改变量的修改不会影响到其它线程。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya2PNptmXEntM7gPKCnknI3UvpTAlrZbo2MKIiaZhuMJWOJIcE7N1Ahy8HgMARSwBTGzAzDm9LtW1ibg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> **总结**

怎么样，没想到教科书上一句简单的“线程共享进程资源”背后竟然会有这么多的知识点吧，**教科书上的知识看似容易，但，并不简单**。







# [堆和栈的区别（转过无数次的文章）](https://mp.weixin.qq.com/s?__biz=MzA5NTM3MjIxMw==&mid=2247484507&idx=1&sn=f87570b981050ae6bc1e59967fdbddcd&chksm=90411281a7369b973f2d7e347d24aaed6d9dbba7ed380dde7e55de7cbb0cb088f2617c9bd792&mpshare=1&scene=24&srcid=0616KxAx6lyJqQ0M5NLxEaXD&sharer_sharetime=1623843956738&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)



## 预备知识—程序的内存分配

一个由C/C++编译的程序占用的内存分为以下几个部分

- 1、栈区（stack）：由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈，线程私有。
- 2、堆区（heap）：一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回
  收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表，呵呵。
- 3、全局区（静态区）（static）：全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 - 程序结束后由系统释放。
- 4、文字常量区：常量字符串就是放在这里的。 程序结束后由系统释放
- 5、程序代码区：存放函数体的二进制代码。

例子程序，这是一个前辈写的，非常详细

```c
#include "stdio.h"

int a = 0;//全局初始化区 

char *p1;//   全局未初始化区    
void main(void)    
{    
  int   b;//   栈    
  char   s[]   =   "abc";//   栈    
  char   *p2;//   栈    
  char   *p3   =   "123456";//   123456/0在常量区，p3在栈上。    
  static   int   c   =0;//   全局（静态）初始化区    
  p1   =   (char   *)malloc(10);    
  p2   =   (char   *)malloc(20);    //分配得来得10和20字节的区域就在堆区。    
  strcpy(p1,   "123456");//   123456/0放在常量区，编译器可能会将它与p3所指向的"123456" 优化成一个地方。       
}
```

## 堆和栈的理论知识

### 申请方式

- stack:
  由系统自动分配。 例如，声明在函数中一个局部变量 int b;
  系统自动在栈中为b开辟空间
- heap:
  需要程序员自己申请，并指明大小，在c中malloc函数
  如p1 = (char *)malloc(10);
  在C++中用new运算符
  如p2 = new char[10];
  但是注意p1、p2本身是在栈中的。

### 申请后系统的响应

- 栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。
- 堆：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时， 会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表 中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的 首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。 另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部 分重新放入空闲链表中。

### 申请大小的限制

- 栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意 思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有 的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将 提示overflow。因此，能从栈获得的空间较小。
- 堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储 的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小 受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。

### 申请效率的比较：

- 栈由系统自动分配，速度较快。但程序员是无法控制的。
- 堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便. 另外，在WINDOWS下，最好的方式是用VirtualAlloc分配内存，他不是在堆，也不是在栈是 直接在进程的地址空间中保留一块内存，虽然用起来最不方便。但是速度快，也最灵活。

### 堆和栈中的存储内容

- 栈： 在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可 执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈 的，然后是函数中的局部变量。注意静态变量是不入栈的。 当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地
  址，也就是主函数中的下一条指令，程序由该点继续运行。
- 堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容由程序员安排。

存取效率的比较

```c
char s1[] = "aaaaaaaaaaaaaaa";
char *s2 = "bbbbbbbbbbbbbbbbb";
```

aaaaaaaaaaa是在运行时刻赋值的；而bbbbbbbbbbb是在编译时就确定的；
但是，在以后的存取中，在栈上的数组比指针所指向的字符串(例如堆)快。
比如：

```c
#include "stdio.h"   

void main(void)    
{    
  char   a   =   1;    
  char   c[]   =   "1234567890";    
  char   *p   ="1234567890";    
  a   =   c[1];    
  a   =   p[1];    
  return;    
}    
  对应的汇编代码    
  10:   a   =   c[1];    
  00401067   8A   4D   F1   mov   cl,byte   ptr   [ebp-0Fh]    
  0040106A   88   4D   FC   mov   byte   ptr   [ebp-4],cl    
  11:   a   =   p[1];    
  0040106D   8B   55   EC   mov   edx,dword   ptr   [ebp-14h]    
  00401070   8A   42   01   mov   al,byte   ptr   [edx+1]    
  00401073   88   45   FC   mov   byte   ptr   [ebp-4],al 
```

第一种在读取时直接就把字符串中的元素读到寄存器cl中，
而第二种则要先把指针值读到 edx中，再根据edx读取字符，显然慢了。

## 小结：

**堆和栈的区别可以用如下的比喻来看出**
使用栈就象我们去饭馆里吃饭，只管点菜（发出申请）、付钱、和吃（使用），吃饱了就走，不必理会切菜、洗菜等准备工作和洗碗、刷锅等扫尾工作，他的好处是快捷，但是自由度小。
使用堆就象是自己动手做喜欢吃的菜肴，比较麻烦，但是比较符合自己的口味，而且自由 度大。 (经典！)

![图片](https://mmbiz.qpic.cn/mmbiz_png/Qof5hj3zMPc1GeKNyrhnLoKgTiawg4YPYPicgGa0kh5huU3XlfELwP0rWTrMaZiaOSclXw9zGGNEpO0dpYsgaWpEw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/Qof5hj3zMPc1GeKNyrhnLoKgTiawg4YPYwWtXARwbZJMofWWz279OTRqF6Z6zWWVkvcPSH4OKHicUdqrJfj0ftWg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



# [内存分配之堆和栈的区别](https://mp.weixin.qq.com/s?__biz=MzI4OTU3ODk3NQ==&mid=2247484458&idx=1&sn=ad6d6af2780d62a5a0f2621c79943c6e&chksm=ec2c4e9adb5bc78cfabc3c1ff6bf4621e3ded51579279c4822e51c9943987c3b59c987ee584f&mpshare=1&scene=24&srcid=0614LXTftJ4wjiZV94pEsSmW&sharer_sharetime=1623604131463&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)



**堆栈概述**

  在计算机领域，堆栈是一个不容忽视的概念，堆栈是两种数据结构。堆栈都是一种数据项按序排列的数据结构，只能在一端(称为栈顶(top))对数据项进行插入和删除。在单片机应用中，堆栈是个特殊的存储区，主要功能是暂时存放数据和地址，通常用来保护断点和现场。

**要点：** 

堆，优先队列(priority queue)；普通的队列是一种先进先出的数据结构（FIFO—First-In/First-Out），元素在队列尾追加，而从队列头删除，（例如：乘车排队，先来的排在前面先上车，后来的就要排的后面后上车; 哎，哎，你怎么插队呢，学没学过队列）；在优先队列中，元素被赋予优先级。当访问元素时，具有最高优先级的元素最先取出。优先队列具有最高级先出 （largest-in，first-out）的行为特征。

栈，先进后出(FILO—First-In/Last-Out)（例如：超市排队结账，大一点的超市收银台都是一段狭长的过道，本来下一个是你了，突然这个收银台说不结了，OK，栈形成了，排在前面的要后出去了）。



## **一、程序的内存分配**

1、一个由C/C++编译的程序占用的内存分为以下几个部分

1）、栈区（stack）

由编译器自动分配释放，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈，线程私有。

2）、堆区（heap）

一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表。

3）、全局区（静态区）（static）

全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 程序结束后由系统释放。 

4）、文字常量区

常量字符串就是放在这里的，程序结束后由系统释放 。

5）、程序代码区

存放函数体的二进制代码。 



2、变量的存储方式

这里写图片描述

![图片](http://mmbiz.qpic.cn/mmbiz_png/XCETLoXzTr8gnRfCjRlSRMXTRODk4uYfGxocTw7QGvadqJIfXAY19nLOHselG1qXGOqRRiaiavLluX9oFLUrWiahw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

  首先，定义静态变量时如果没有初始化编译器会自动初始化为0.。接下来，如果是使用常量表达式初始化了变量，则编译器仅根据文件内容（包括被包含的头文件）就可以计算表达式，编译器将执行常量表达式初始化。必要时，编译器将执行简单计算。如果没有足够的信息，变量将被动态初始化。请看一下代码：

![图片](http://mmbiz.qpic.cn/mmbiz_png/XCETLoXzTr8gnRfCjRlSRMXTRODk4uYfdLH0MYgdzucnvnbic2HHznsdZs0uz5CfR9cm867eibxqglRQlx8uqMqQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

  所有的静态持续变量都有下述初始化特征：未被初始化的静态变量的所有位都被设为0。这种变量被称为零初始化。以上代码说明关键字static的两种用法，但含义有些不同：用于局部声明，以指出变量是无链接性的静态变量时，static表示的是存储持续性；而用于代码块外声明时，static表示内部链接性，而变量已经是静态持续性了。有人称之为关键字重载，即关键字的含义取决于上下文。



## **二、C/C++堆和栈的区别**

​    1.管理方式不同

栈，由编译器自动管理，无需程序员手工控制；堆：产生和释放由程序员控制。

2. 空间大小不同

栈的空间有限；堆内存可以达到4G。

3. 能否产生碎片不同

栈不会产生碎片，因为栈是种先进后出的队列。堆则容易产生碎片，多次的new/delete会造成内存的不连续，从而造成大量的碎片。

4. 生长方向不同

堆的生长方式是向上的，栈是向下的。

5. 分配方式不同

堆是动态分配的。栈可以是静态分配和动态分配两种，但是栈的动态分配由编译器释放。

6. 缓存级别不同：

　　1)、栈使用的是一级缓存， 他们通常都是被调用时处于存储空间中，调用完毕立即释放； 

　　2)、堆是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）。所以调用这些对象的速度要相对来得低一些。

7. 分配效率不同

  栈是机器系统提供的数据结构，计算机底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令。堆则是由C/C++函数库提供，库函数会按照一定的算法在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。 

  堆和栈相比，由于大量new/delete的使用，容易造成大量的内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和核心态的切换，内存的申请，代价变得更加昂贵。所以栈在程序中是应用最广泛的，就算是函数的调用也利用栈去完成，函数调用过程中的参数，返回地址，EBP和局部变量都采用栈的方式存放。所以，我们推荐大家 尽量用栈，而不是用堆。 

  栈和堆相比不是那么灵活，有时候分配大量的内存空间，还是用堆好一些。 

  无论是堆还是栈，都要防止越界现象的发生。

例子程序

![图片](http://mmbiz.qpic.cn/mmbiz_png/XCETLoXzTr8gnRfCjRlSRMXTRODk4uYfGnYRrg7hcl90yfHHNIyicwJ2ybJoVRSUXukJWXoNMrdjOMkib2xOFQqA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



## **三、java堆和栈的区别**

1. 栈(stack)与堆(heap)都是Java用来在Ram中存放数据的地方。

与C++不同，Java自动管理栈和堆，程序员不能直接地设置栈或堆。

2. 栈的优势是，存取速度比堆要快，仅次于直接位于CPU中的寄存器。

但缺点是，存在栈中的数据大小与生存期必须是确定的，缺乏灵活性。另外，栈数据在多个线程或者多个栈之间是不可以共享的，但是在栈内部多个值相等的变量是可以指向一个地址的，详见第3点。堆的优势是可以动态地分配内存大小，生存期也不必事先告诉编译器，Java的垃圾收集器会自动收走这些不再使用的数据。但缺点是，由于要在运行时动态分配内存，存取速度较慢。

   3.Java中的数据类型有两种。

一种是基本类型(primitivetypes), 共有8种，即int,short, long, byte, float, double, boolean, char(注意，并没有string的基本类型)。这种类型的定义是通过诸如int a= 3; long b = 255L;的形式来定义的，称为自动变量。值得注意的是，自动变量存的是字面值，不是类的实例，即不是类的引用，这里并没有类的存在。如int a= 3; 这里的a是一个指向int类型的引用，指向3这个字面值。这些字面值的数据，由于大小可知，生存期可知(这些字面值固定定义在某个程序块里面，程序块退出后，字段值就消失了)，出于追求速度的原因，就存在于栈中。 

另外，栈有一个很重要的特殊性，就是存在栈中的数据可以共享。假设我们同时定义：

```c
int a=3;
int b=3;
```

编译器先处理int a= 3；首先它会在栈中创建一个变量为a的内存空间，然后查找有没有字面值为3的地址，没找到，就开辟一个存放3这个字面值的地址，然后将a指向3的地址。接着处理int b= 3；在创建完b的引用变量后，由于在栈中已经有3这个字面值，便将b直接指向3的地址。这样，就出现了a与b同时均指向3的情况。 

特别注意的是，这种字面值的引用与类对象的引用不同。假定两个类对象的引用同时指向一个对象，如果一个对象引用变量修改了这个对象的内部状态，那么另一个对象引用变量也即刻反映出这个变化。相反，通过字面值的引用来修改其值，不会导致另一个指向此字面值的引用的值也跟着改变的情况。如上例，我们定义完a与b的值后，再令a=4；那么，b不会等于4，还是等于3。在编译器内部，遇到a=4；时，它就会重新搜索栈中是否有4的字面值，如果没有，重新开辟地址存放4的值；如果已经有了，则直接将a指向这个地址。因此a值的改变不会影响到b的值。 

另一种是包装类数据，【如Integer,String, Double等将相应的基本数据类型包装起来的类。这些类数据全部存在于【堆】中】，Java用new()语句来显示地告诉编译器，在运行时才根据需要动态创建，因此比较灵活，但缺点是要占用更多的时间。 4.String是一个特殊的包装类数据。即可以用String str = new String(“abc”);的形式来创建，也可以用Stringstr = “abc”；的形式来创建(作为对比，在JDK 5.0之前，你从未见过Integer i = 3;的表达式，因为类与字面值是不能通用的，除了String。而在JDK5.0中，这种表达式是可以的！因为编译器在后台进行Integer i = new Integer(3)的转换)。前者是规范的类的创建过程，即在Java中，一切都是对象，而对象是类的实例，全部通过new()的形式来创建。Java中的有些类，如DateFormat类，可以通过该类的getInstance()方法来返回一个新创建的类，似乎违反了此原则。其实不然。该类运用了单例模式来返回类的实例，只不过这个实例是在该类内部通过new()来创建的，而getInstance()向外部隐藏了此细节。那为什么在String str = “abc”；中，并没有通过new()来创建实例，是不是违反了上述原则？其实没有。



4. 关于String str = “abc”的内部工作。

Java内部将此语句转化为以下几个步骤：【String str = “abc”，String str不要连着】 

(1)先定义一个名为str的对String类的对象引用变量：String str； 

(2)【在【栈】中查找有没有存放值为”abc”的地址，如果没有，则开辟一个存放字面值为”abc”的地址，接着创建一个新的String类的对象o，并将o的字符串值指向这个地址，而且在栈中这个地址旁边记下这个引用的对象o。如果已经有了值为”abc”的地址，则查找对象o，并返回o的地址。】【上文说数据时存放在堆中，此文说数据存放在栈中】[因为此处不是通过new（）创建的啊] 

(3)将str指向对象o的地址。 

值得注意的是，一般String类中字符串值都是直接存值的。但像String str = “abc”；这种场合下，其字符串值却是保存了一个指向存在栈中数据的引用！ 

为了更好地说明这个问题，我们可以通过以下的几个代码进行验证。 

```c
String str1="abc";String str2="abc";
System.out.println(str1==str2);//true
```

注意，我们这里并不用str1.equals(str2)；的方式，因为这将比较两个字符串的值是否相等。==号，根据JDK的说明，只有在两个引用都指向了同一个对象时才返回真值。而我们在这里要看的是，str1与str2是否都指向了同一个对象。  

　　结果说明，JVM创建了两个引用str1和str2，但只创建了一个对象，而且两个引用都指向了这个对象。 

我们再来更进一步，将以上代码改成： 
```c
String str1="abc";
String str2="abc";
str1="bcd";
System.out.println(str1+","+str2);//bcd,abcSystem.out.println(str1==str2);//false
```
这就是说，赋值的变化导致了类对象引用的变化，str1指向了另外一个新对象！而str2仍旧指向原来的对象。上例中，当我们将str1的值改为”bcd”时，JVM发现在栈中没有存放该值的地址，便开辟了这个地址，并创建了一个新的对象，其字符串的值指向这个地址。 

事实上，String类被设计成为不可改变(immutable)的类。如果你要改变其值，可以，但JVM在运行时根据新值悄悄创建了一个新对象，然后将这个对象的地址返回给原来类的引用。这个创建过程虽说是完全自动进行的，但它毕竟占用了更多的时间。在对时间要求比较敏感的环境中，会带有一定的不良影响。 

再修改原来代码： 
```c
String str1="abc";String str2="abc";
str1="bcd";String str3=str1;
System.out.println(str3);//bcdString str4="bcd";
System.out.println(str1==str4);//true
```
我们再接着看以下的代码。 
```c
String str1 = new String("abc"); 
String str2 = "abc"; 
System.out.println(str1==str2); //falseString str1 = "abc"; 
String str2 = new String("abc"); 
System.out.println(str1==str2); //false 
```
创建了两个引用。创建了两个对象。两个引用分别指向不同的两个对象。 

以上两段代码说明，只要是用new()来新建对象的，都会在堆中创建，而且其字符串是单独存值的，即使与栈中的数据相同，也不会与栈中的数据共享。



5. 数据类型包装类的值不可修改。

不仅仅是String类的值不可修改，所有的数据类型包装类都不能更改其内部的值。



6. 结论与建议：

(1)我们在使用诸如String str = “abc”；的格式定义类时，总是想当然地认为，我们创建了String类的对象str。担心陷阱！对象可能并没有被创建！唯一可以肯定的是，指向String类的引用被创建了。至于这个引用到底是否指向了一个新的对象，必须根据上下文来考虑，除非你通过new()方法来显要地创建一个新的对象。因此，更为准确的说法是，我们创建了一个指向String类的对象的引用变量str，这个对象引用变量指向了某个值为”abc”的String类。清醒地认识到这一点对排除程序中难以发现的bug是很有帮助的。 

(2)使用String str = “abc”；的方式，可以在一定程度上提高程序的运行速度，因为JVM会自动根据栈中数据的实际情况来决定是否有必要创建新对象。而对于Stringstr = new String(“abc”)；的代码，则一概在堆中创建新对象，而不管其字符串值是否相等，是否有必要创建新对象，从而加重了程序的负担。这个思想应该是享元模式的思想，但JDK的内部在这里实现是否应用了这个模式，不得而知。 

(3)当比较包装类里面的数值是否相等时，用equals()方法；当测试两个包装类的引用是否指向同一个对象时，用==。 

(4)由于String类的immutable性质，当String变量需要经常变换其值时，应该考虑使用StringBuffer类，以提高程序效率



# [堆和栈的区别（非常详细，干货收藏！）](https://mp.weixin.qq.com/s?__biz=MzU5NzA3MDQxMA==&mid=2247493631&idx=2&sn=e779c341ac0c6a15771f4bc32f5eb262&chksm=fe5ba0dac92c29cc2caf600926b834f554c096b1554fc24a8719ad2b6cc16167ced31632c9fe&mpshare=1&scene=24&srcid=0614wLvhXGhhZF4jIFyv7N1U&sharer_sharetime=1623604097197&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)



**▍预备知识—程序的内存分配**

一个由C/C++编译的程序占用的内存分为以下几个部分

- **1、栈区（stack）：**由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈,，线程私有。



- **2、堆区（heap）：**一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表，呵呵。



- **3、全局区（静态区）（static）：**全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。- 程序结束后由系统释放。



- **4、文字常量区：**常量字符串就是放在这里的。程序结束后由系统释放。



- **5、程序代码区：**存放函数体的二进制代码。

**例子程序**

![图片](https://mmbiz.qpic.cn/mmbiz_png/MLfSTncC3tM9wW6ib1vzfoPScKeLia11Re4hOibWek0OeRtibq8414cvTKky0DtcSfmnteSkmgBXiam7Oe0DbwUJppw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## ▍堆和栈的理论知识

### 申请方式

- **stack:**
  由系统自动分配。例如，声明在函数中一个局部变量 int b; 系统自动在栈中为b开辟空间



- **heap:** 
  需要程序员自己申请，并指明大小，在c中malloc函数
  
  如p1 = (char *)malloc(10); 
  
  在C++中用new运算符 
  如p2 = new char[10]; 
  但是注意p1、p2本身是在栈中的。

### 申请后系统的响应

- **栈：**只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。



- **堆：**首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时， 会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表 中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的 首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部 分重新放入空闲链表中。

### 申请大小的限制

- **栈：**在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意 思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有 的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将 提示overflow。因此，能从栈获得的空间较小。



- **堆：**堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储 的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小 受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。

### 申请效率的比较

- 栈由系统自动分配，速度较快。但程序员是无法控制的。



- 堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便. 另外，在WINDOWS下，最好的方式是用VirtualAlloc分配内存，他不是在堆，也不是在栈是 直接在进程的地址空间中保留一块内存，虽然用起来最不方便。但是速度快，也最灵活。

### 堆和栈中的存储内容

- **栈：**在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可 执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈 的，然后是函数中的局部变量。注意静态变量是不入栈的。当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。

  

- **堆：**一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容由程序员安排。

**存取效率的比较**

```c
char s1[] = "aaaaaaaaaaaaaaa"; 
char *s2 = "bbbbbbbbbbbbbbbbb"; 
```



aaaaaaaaaaa是在运行时刻赋值的； 
	    而bbbbbbbbbbb是在编译时就确定的； 

但是，在以后的存取中，在栈上的数组比指针所指向的字符串(例如堆)快。 

比如：

![图片](https://mmbiz.qpic.cn/mmbiz_png/MLfSTncC3tM9wW6ib1vzfoPScKeLia11Re92jZYkRqHumuWWWRJdt7zB6PLrbSfyqcLlV5mKicX7EaZDzRkOx605g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

第一种在读取时直接就把字符串中的元素读到寄存器cl中，
而第二种则要先把指针值读到 edx中，再根据edx读取字符，显然慢了。

## **▍小结：**

**堆和栈的区别可以用如下的比喻来看出**

使用栈就象我们去饭馆里吃饭，只管点菜（发出申请）、付钱、和吃（使用），吃饱了就走，不必理会切菜、洗菜等准备工作和洗碗、刷锅等扫尾工作，他的好处是快捷，但是自由度小。

使用堆就象是自己动手做喜欢吃的菜肴，比较麻烦，但是比较符合自己的口味，而且自由度大。(经典！)



# [C语言面试题详解指针篇，不知道内存分几个区，不是合格的程序员](https://mp.weixin.qq.com/s?__biz=MzIzNjgxNjA3MQ==&mid=2247484988&idx=1&sn=f366c998dd8c3b5cbe7febdadbcf74bc&chksm=e8d35594dfa4dc82302f9abc19de73f3d6f047053c700c378269ffa7ab42857dda3348be95ca&scene=0&xtrack=1#rd)

C语言面试题指针篇第3节，不理解内存空间的程序员，是不合格的

分析下面代码：

```c
# include <stdio.h>
# include <stdlib.h>
# include <string.h>

void getmemory( char *p){
    p=( char *) malloc(100);
    strcpy(p,"hello world");
}
   
int main( void){
    char *str=NULL;
    getmemory(str);
    printf("%s ",str);
    free(str);
    return 0;
}
```



答案：程序崩溃， getmemory 中的 malloc 不不能返回动态内存， free() 对 str 操作很危险，程序会崩溃，出现段错误这道题目初一看跟我们前面的一道题目非常相像，但是却又截然不同。

在该程序中， getmemory 中 p 是形参，所谓形参在运行中会产生一个临时变量，只会把外界传入的参数的值接收到，所有的改变不会影响外界的实际参数。 getmemory 函数中，因为我们要改变传入的str指针的指向，也就是说要改变str指针变量的值，应该传入的是指针变量的地址。

因此在函数的形参中不应该写 char *p ，而是应该是 char **p 。getmemory(str) 调用后，传入的是指针变量保存的对象地址，p=(char *) malloc(100) 实际上是把申请的动态内存空间的首地址付给p这个临时变量，改变了p的指向，对于外界的str是没有影响的，因此这个是错误的。

应该修改成指向指针的指针void getmemory(char **p) ，这样 malloc 返回的地址付给 p（即str变量本身）。

来看另外的一道题目：

下面函数有什么问题，应该怎么修改

```c
char *strA()
{
    char str[] ="hello world";
	return str;
}
```



分析：

因为这个函数返回的是局部变量的地址，当调用这个函数后，这个局部变量str就释放了，所以返回的结果是不不确定的且不不安全，随时都有被收回的可能。这个str里存在的地址是函数strA栈里“hello world”的首地址。

函数调用完成，栈帧恢复调用strA之前的状态，临时空间被重置，堆栈“回缩”，strA栈帧不再属于应该访问的范围。

这段程序可以正确输出结果，但是这种访问方法违背了函数的栈帧机制。但是只要另外一个函数调用的话，你就会发现，这种方式的不合理及危险性。

如果想获得正确的函数，改成下面这样就可以：

```c
char *strA()
{
	char * str ="hello world";
 	return str;
}
```



首先要搞清楚char *str 和 char str[] 的区别：

1、

```c
char str[] = "hello world";
```

是分配一个局部数组。局部数组是局部变量，它所对应的是内存中的栈。局部变量的生命周期结

束后该变量不存在了。

2、

```c
char * str = "hello world";
```

是指向了了常量区的字符串，位于静态存储区，它在程序生命期内恒定不变，所以字符串还在。

无论什么时候调用 strA，它返回的始终是同一个“只读”的内存块。

另外想要修改，也可以这样：通过static开辟一段静态存贮空间。

```c
char *strA()
{
    static char str[] ="hello world";
    return str;
}
```



因为指针本身使用的复杂性与普适性，所以考点非常多，而且也可以与其他知识相互结合，

因此我们将会使用五篇专题的篇幅来介绍指针。分析下面的程序,指出程序中的错误：

```c
# include <stdio.h>

int main( void)
{
    char a;
    char *str=&a;
    strcpy(str,"hello");
    printf("%s ",str);
    return 0;
}
```



**本题解析**

没有正确为str分配内存空间，将会发生异常。

问题出在将一个字符串复制进一个字符变量指针所指地址。

虽然编译的时候没有报错，但是在运行过程中，因为越界访问了未被分配的内存，而导致段错误。



## 相关知识点

在处理与指针相关的问题时，首先需要搞明白的就是内存，因为指针操作的就是内存。

第一个，就是内存的分区。这也是经常会被考察的一个考点。

**写出内存分为几大区域**

对于这个问题，有几种不不同的说法。

有的说内存分为五大分区，有的说分为四大分区，我们先来先看五个分区的说法：

认为内存分为五大分区的人，通常会这样划分：

### 1、BSS段( bss segment )

通常是指用来存放程序中未初始化的全局变量和静态变量 （这里注意一个问题:一般的书上都会说全局变量和静态变量是会自动初始化的,那么哪来的未初始化的变量呢?变量的初始化可以分为显示初始化和隐式初始化,全局变量和静态变量如果程序员自己不初始化的话的确也会被初始化,那就是不管什么类型都初始化为0,这种没有显示初始化的就是我们这里所说的未初始化。既然都是0那么就没必要把每个0都存储起来,从而节省磁盘空间,这是BSS的主要作用）的一块内存区域。BSS是英文Block Started by Symbol的简称。BSS段属于静态内存分配。BSS节不不包含任何数据,只是简单的维护开始和结束的地址,即总大小。以便内存区能在运行时分配并被有效地清零。BSS节在应用程序的二进制映象文件中并不存在,即不占用磁盘空间而只在运行的时候占用内存空间 ,所以如果全局变量和静态变量未初始化那么其可执行文件要小很多。

### 2、数据段(data segment)

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/sMARbZtTY5elM4sEoB6VDU5xwEicIAMngxcAjyamrQHiatxKk425Ng8CXJtWYZnYK8tYOevsgJYquoLoKQnV5gEw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



通常是指用来存放程序中已经初始化的全局变量和静态变量的一块内存区域。

数据段属于静态内存分配,可以分为只读数据段和读写数据段。

字符串常量等,但一般都是放在只读数据段中。

### 3、代码段(code segment/text segment)

通常是指用来存放程序执行代码的一块内存区域。

这部分区域的大小在程序运行前就已经确定,

并且内存区域通常属于只读, 某些架构也允许代码段为可写,即允许修改程序。

在代码段中,也有可能包含一些只读的常数变量,例例如字符串常量等,但一般都是放在只读数据段中 。

### 4、堆(heap)

堆是用于存放进程运行中被动态分配的内存段,它的大小并不固定,可动态扩张或缩减。

当进程调用malloc等函数分配内存时,新分配的内存就被动态添加到堆上(堆被扩张);

当利用free等函数释放内存时,被释放的内存从堆中被剔除(堆被缩减)

### 5、栈 (stack)

栈又称堆栈, 是用户存放程序临时创建的局部变量,也就是说我们函数括弧“{}” 中定义

的变量(但不不包括static声明的变量,static意味着在数据段中存放变量)。

除此以外, 在函数被调用时,其参数也会被压入发起调用的进程栈中,并且待到调用结束后,

函数的返回值也会被存放回栈中。由于栈的先进先出特点,所以 栈特别方便用来保存/恢复调用现场。

从这个意义上讲,我们可以把堆栈看成一个寄存、交换临时数据的内存区。

## 而四大分区的说法，则这么认为：

**1、堆区：**

由程序员手动申请，手动释放，若不手动释放，程序结束后由系统回收，生命周期是整个程序运

行期间。使用malloc或者new进行堆的申请，堆的总大小为机器器的虚拟内存的大小。

说明：new操作符本质上是使用了malloc进行内存的申请，new和malloc的区别如下：

（1）malloc是C语言中的函数，而new是C++中的操作符。

（2）malloc申请之后返回的类型是void*，而new返回的指针带有类型。

（3）malloc只负责内存的分配而不会调用类的构造函数，而new不仅会分配内存，

而且会自动调用类的构造函数。

**2、栈区：**

由系统进行内存的管理理。主要存放函数的参数以及局部变量。

在函数完成执行，系统自行释放栈区内存，不需要用户管理。

整个程序的栈区的大小可以在编译器器中由用户自行设定，

VS中默认的栈区大小为1M，可通过VS手动更改栈的大。

64bits的Linux默认栈大小为10MB，可通过ulimit-s临时修改。

**3、静态存储区：**

静态存储区内的变量在程序编译阶段已经分配好内存空间并初始化。这块内存在程序的整个运行期间都存在，它主要存放静态变量、全局变量和常量。

**注意：**

（1）这里不区分初始化和未初始化的数据区，是因为静态存储区内的变量若不显示初始化，则编译器会自动以默认的方式进行初始化，即静态存储区内不存在未初始化的变量。

（2）静态存储区内的常量分为常变量和字符串常量，一经初始化，不可修改。静态存储内的常变量是全局变量，与局部常变量不不同，区别在于局部常变量存放于栈，实际可间接通过指针或者引用进行修改，而全局常变量存放于静态常量区则不可以间接修改。

（3）字符串常量存储在静态存储区的常量区，字符串常量的名称即为它本身，属于常变量。

（4）数据区的具体划分，有利利于我们对于变量类型的理理解。

不同类型的变量存放的区域不同。后面将以实例代码说明这四种数据区中具体对应的变量。

**4、代码区：**

存放程序体的二进制代码。比如我们写的函数，都是在代码区的。

通过上面的不同说法，我们也可以看出，这两种说法本身没有优劣之分，

具体的内存划分也跟编译器有很大的关系，因此这两种说法都是可以接受的，

搞明白内存的分区之后，指针的使用才能够更更加的灵活



# [把内存管理理解好，C语言真的不难学。今天带你“攻破”内存管理](https://mp.weixin.qq.com/s?__biz=MzUxMjEyNDgyNw==&mid=2247499159&idx=1&sn=81a4622db90967592927379feaa0bb6f&chksm=f96b8f63ce1c06757bf50fecc6470b859a81339a678b80ad268471708b571357a53cd2412d17&mpshare=1&scene=24&srcid=1110VFHECRxm8sBWx0XoZAVQ&sharer_sharetime=1636516394722&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)

任何程序运行起来都需要分配内存空间存放该进程的资源信息的，C程序也不例外。C程序中的变量、常量、函数、代码等等的信息所存放的区域都有所不同，不同的区域又有不同的特性。C语言学习者、尤其是在学习嵌入式的朋友，这些知识点一定要吃透！

![图片](https://mmbiz.qpic.cn/mmbiz_png/icRxcMBeJfc9IgyoFSekF56yR659WjR1ia98ibUAqtR2SnSQV65jFrbGYW76QWtib4jliazQuOtTDt86w3fiaKTyXL4w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



## 被欺骗的C进程

每一个C语言的程序被执行起来的时候系统为了更方便开发人员操作，会给每一个进程分配一个虚拟的内存空间，它实际上是从处理内存映射出来的。虚拟内存的起始地址结束地址都是固定的，因此虚拟内存的布局都是一样。比如有三个进程 P1 P2 P3 ,他们虽然得到的物理内存是完全不一样，但是从进程的角度来看他们三个得到的内存确实一模一样的。



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/icRxcMBeJfc9IgyoFSekF56yR659WjR1iaXJId7ccmJ7maicD7FW8kibiaAM2Z25ceNhu8W2FufVbYIcENcvRGyhQ9w/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



假设你正在使用的计算机实际物理内存只有 1GB 大小，而当前系统运行了三个进程，Linux 会将 PM 中的某些内存映射为三个大小均为 4GB 的虚拟内存 ，让每个进程都以为自己独自拥有了完整的内存空间，这样极大地方 便了应用层程序的数据和代码的组织。

## 虚拟内存布局：

虚拟内存布局分为内核空间、栈、堆、数据段、代码段和一个不允许访问的空间（相当于一堵墙）。



![图片](https://mmbiz.qpic.cn/mmbiz_png/icRxcMBeJfc9IgyoFSekF56yR659WjR1iaXE9ME7mtibzLLcw7rsEbK5qQONpxkDfcy0ic2HjCDicva4ItDX3DUj9nQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



一个用户进程可以访问的内存区域介于 0x0804 8000 到0xc0000000 之间，这个“广袤”的区域又被分成了几个部分，分别用来存放进程的代码和数据。

**下面让我们更进一步地研究虚拟内存中每一个空间所存放的是什么类型的数据。**

## 栈内存

栈内存是用于存放环境变量、命令行参数和局部变量的。栈内存空间十分有限，默认情况下栈的大小为 8M ，在嵌入式开发的时候我们应该尽可能减少使用栈空间。栈空间的增长，从上（高地址） 往下 （低地址）每当有一个函数被调用的时候，栈就会从上往下分配一个段，这一段空间就是一个栈帧，该内存空间用来存放该函数的局部变量。



![图片](https://mmbiz.qpic.cn/mmbiz_png/icRxcMBeJfc9IgyoFSekF56yR659WjR1iaU81dibT31F5gTaPPjbiaTojqo4Hzcy9Dicx0O6WDoiaPhxWk6YTwsSBDrw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





当一个函数退出（调用结束）的时候，栈空间会从下往上释放一个栈帧，将所有的内存归还给系统。

注意：

栈空间中的内存存放的数据值是未知的， 因此每一个局部变量在使用之前最好做好初始化

栈内存的空间我们无法手动实现申请与释放，都是由系统自动完成，我们无法干预。



## 堆空间

堆空间是相对自由的空间，这是一个非常重要的区域，因为在此区域定义的内存的 生命周期我们是可以控制的：从 malloc( )/calloc( )/realloc( )开始，到 free( )结束，其分配和释放完全由我们开发者自定义，这就给了我们最大的自由和灵活性，让程序在运行的过 程当中，以最大的效益使用内存。

![图片](https://mmbiz.qpic.cn/mmbiz_png/icRxcMBeJfc9IgyoFSekF56yR659WjR1iaN2ibrLmolZZkRXPW6JmvLhiaVR9q2A7debkl7GeIZTt7SdQ43icAwGXTw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)**注意：**

- 相对于栈空间来说，堆的内存空间相对大很多
- 堆空间的增长方式，从下（低地址）往上（高地址）
- 堆空间中的内存都属于匿名空间， 因此需要借助指针来访问
- 有开发者自行申请和释放的，如果没有释放那么这个空间将一直存在，直到程序结束。

## 数据段

数据段中存放着全局变量、静态变量、和常量这些数据，生命周期与程序一致。程序不止，数据不断（段）。



![图片](https://mmbiz.qpic.cn/mmbiz_png/icRxcMBeJfc9IgyoFSekF56yR659WjR1iaskBuGpRuW2icpOibYcgclMVz72JETadnUALGibBRE7GIunrUuPEFn5Eeg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 代码段

代码段中又分成了两个空间：

.text段：存放用户的代码（mian func ...）

init段：当程序运行之初的一些初始化的工作（由编译器根据系统来对应添加的）

![图片](https://mmbiz.qpic.cn/mmbiz_png/icRxcMBeJfc9IgyoFSekF56yR659WjR1iaicnQm89Q9OG2qhFcY7W2fItsx5B7dKn6yDoJT2Ymb0QPfadFuW7Cq6Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

内存管理是嵌入式学习的重点知识，也是判断一个人是否入门的重要标志。内存管理学得好，对C语言的理解又会更加深刻一些。



# [看完这篇你还能不懂C语言/C++内存管理？](https://mp.weixin.qq.com/s?__biz=MzUxMjEyNDgyNw==&mid=2247495988&idx=1&sn=2c6af247d80989d0e23c358407d73397&chksm=f96b83c0ce1c0ad6531675a30396cc70ddbb6a377604890b82d92e98698706f9288095a8c87f&mpshare=1&scene=24&srcid=0716tozNVx1RXWxtCOPZTRCE&sharer_sharetime=1626407698049&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)

C 语言内存管理指对系统内存的分配、创建、使用这一系列操作。在内存管理中，由于是操作系统内存，使用不当会造成毕竟麻烦的结果。本文将从系统内存的分配、创建出发，并且使用例子来举例说明内存管理不当会出现的情况及解决办法。

## 一、内存

在计算机中，每个应用程序之间的内存是相互独立的，通常情况下应用程序 A 并不能访问应用程序 B，当然一些特殊技巧可以访问，但此文并不详细进行说明。例如在计算机中，一个视频播放程序与一个浏览器程序，它们的内存并不能访问，每个程序所拥有的内存是分区进行管理的。

在计算机系统中，运行程序 A 将会在内存中开辟程序 A 的内存区域 1，运行程序 B 将会在内存中开辟程序 B 的内存区域 2，内存区域 1 与内存区域 2 之间逻辑分隔。

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6P0jjm21ZgRgUADxXsxbIzHCUnmFCUtkmVvYwqcfQcPsj6hJvUiblzzA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 1.1 内存四区

在程序 A 开辟的内存区域 1 会被分为几个区域，这就是**内存四区**，内存四区分为栈区、堆区、数据区与代码区。

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6ia9YqOPfrJ15r1BDBVrN4YZrdNC79QkvrI1aibsicibbdCg9aYwYzAIA3g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

栈区指的是存储一些临时变量的区域，临时变量包括了局部变量、返回值、参数、返回地址等，当这些变量超出了当前作用域时将会自动弹出。该栈的最大存储是有大小的，该值固定，超过该大小将会造成栈溢出。

堆区指的是一个比较大的内存空间，主要用于对动态内存的分配；在程序开发中一般是开发人员进行分配与释放，若在程序结束时都未释放，系统将会自动进行回收。

数据区指的是主要存放全局变量、常量和静态变量的区域，数据区又可以进行划分，分为全局区与静态区。全局变量与静态变量将会存放至该区域。

代码区就比较好理解了，主要是存储可执行代码，该区域的属性是只读的。

### 1.2 使用代码证实内存四区的底层结构

由于栈区与堆区的底层结构比较直观的表现，在此使用代码只演示这两个概念。首先查看代码观察栈区的内存地址分配情况：

```c
#include<stdio.h>
int main()
{
 int a = 0;
 int b = 0;
 char c='0';
 printf("变量a的地址是：%d\n变量b的地址是：%d\n变量c的地址是：%d\n", &a, &b, &c);

}
```

运行结果为：

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6iaAPI0I52TR2NRImXKVNpMhiaCTPD8ruTxlbaicRIAsTTblzHiajlVYQZg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

我们可以观察到变量 a 的地址是 2293324 变量 b 的地址是 2293320，由于 int 的数据大小为 4 所以两者之间间隔为 4；再查看变量 c，我们发现变量 c 的地址为 2293319，与变量 b 的地址 2293324 间隔 1，因为 c 的数据类型为 char，类型大小为 1。在此我们观察发现，明明我创建变量的时候顺序是 a 到 b 再到 c，为什么它们之间的地址不是增加而是减少呢？那是因为栈区的一种数据存储结构为先进后出，如图：

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD60e5f2wuNr18Y8Nq7sokDN4pZIekSBYRGic4EgOODEmickkJQUaBxoLicQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

首先栈的顶部为地址的“最小”索引，随后往下依次增大，但是由于堆栈的特殊存储结构，我们将变量 a 先进行存储，那么它的一个索引地址将会是最大的，随后依次减少；第二次存储的值是 b，该值的地址索引比 a 小，由于 int 的数据大小为 4，所以在 a 地址为 2293324 的基础上往上减少 4 为 2293320，在存储 c 的时候为 char，大小为 1，则地址为 2293319。由于 a、b、c 三个变量同属于一个栈内，所以它们地址的索引是连续性的，那如果我创建一个静态变量将会如何？在以上内容中说明了静态变量存储在静态区内，我们现在就来证实一下：

```c
#include<stdio.h>
int main()
{
 
 int a = 0;
 int b = 0;
 char c='0';
 static int d = 0;
 
 printf("变量a的地址是：%d\n变量b的地址是：%d\n变量c的地址是：%d\n", &a, &b, &c);
 
 printf("静态变量d的地址是：%d\n", &d);

}
```

运行结果如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6Ed136YRYLL1Df60Za2YxorJ8YpKUCntLjibricelSqibficoz5zfYVjMTA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

以上代码中创建了一个变量 d，变量 d 为静态变量，运行代码后从结果上得知，静态变量 d 的地址与一般变量 a、b、c 的地址并不存在连续，他们两个的内存地址是分开的。那接下来在此建一个全局变量，通过上述内容得知，全局变量与静态变量都应该存储在静态区，代码如下：

```c
#include<stdio.h>
int e = 0;
int main()
{
 
 int a = 0;
 int b = 0;
 char c='0';
 static int d = 0;
 
 printf("变量a的地址是：%d\n变量b的地址是：%d\n变量c的地址是：%d\n", &a, &b, &c);
 
 printf("静态变量d的地址是：%d\n", &d);
 printf("全局变量e的地址是：%d\n", &e);

}
```

运行结果如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6R6b3LJWDg6zC4py03cp4hFBgW9ZQfdic4GIDnJwYA8MUzpERWdtVKLQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

从以上运行结果中证实了上述内容的真实性，并且也得到了一个知识点，栈区、数据区都是使用栈结构对数据进行存储。

在以上内容中还说明了一点栈的特性，就是容量具有固定大小，超过最大容量将会造成栈溢出。查看如下代码：

```c
#include<stdio.h>

int main()
{
 char arr_char[1024*1000000];
    arr_char[0] = '0';
}
```

以上代码定义了一个字符数组 arr_char，并且设置了大小为 1024*1000000，设置该数据是方便查看大小；随后在数组头部进行赋值。运行结果如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6pEDlbvRhDJt2M6TQn2Xgw2yEoAGu8kpSXMuotpX2dubqhEgjORyTew/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这是程序运行出错，原因是造成了栈的溢出。在平常开发中若需要大容量的内存，需要使用堆。

堆并没有栈一样的结构，也没有栈一样的先进后出。需要人为的对内存进行分配使用。代码如下：

```c
#include<stdio.h>
#include<string.h>
#include <malloc.h>
int main()
{
 char *p1 = (char *)malloc(1024*1000000);
 strcpy(p1, "这里是堆区");
 printf("%s\n", p1);
}
```

以上代码中使用了strcpy 往手动开辟的内存空间 p1 中传数据“这里是堆区”，手动开辟空间使用 malloc，传入申请开辟的空间大小 1024*1000000，在栈中那么大的空间必定会造成栈溢出，而堆本身就是大容量，则不会出现该情况。随后输出开辟的内存中内容，运行结果如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6icvVTIq6Pv88NfZAKAZns4Ccqv1YyBekfgLEblJL1e1ZsBBoIGJeQSQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在此要注意p1是表示开辟的内存空间地址。

## 二、malloc 和 free

在 C 语言（不是 C++)中，malloc 和 free 是系统提供的函数，成对使用，用于从堆中分配和释放内存。malloc 的全称是 memory allocation 译为“动态内存分配”。

### 2.1 malloc 和 free 的使用

在开辟堆空间时我们使用的函数为 malloc，malloc 在 C 语言中是用于申请内存空间，malloc 函数的原型如下：

```c
void *malloc(size_t size);
```

在 malloc 函数中，size 是表示需要申请的内存空间大小，申请成功将会返回该内存空间的地址；申请失败则会返回 NULL，并且申请成功也不会自动进行初始化。

细心的同学可能会发现，该函数的返回值说明为 void *，在这里 void * 并不指代某一种特定的类型，而是说明该类型不确定，通过接收的指针变量从而进行类型的转换。在分配内存时需要注意，即时在程序关闭时系统会自动回收该手动申请的内存 ，但也要进行手动的释放，保证内存能够在不需要时返回至堆空间，使内存能够合理的分配使用。

释放空间使用 free 函数，函数原型如下：

```c
void free(void *ptr);
```

free 函数的返回值为 void，没有返回值，接收的参数为使用 malloc 分配的内存空间指针。一个完整的堆内存申请与释放的例子如下：

```c
#include<stdio.h>
#include<string.h>
#include <malloc.h>

int main() {
    int n, *p, i;
    printf("请输入一个任意长度的数字来分配空间:");
    scanf("%d", &n);
    
    p = (int *)malloc(n * sizeof(int));
 if(p==NULL){
  printf("申请失败\n");
  return 0;
 }else{
  printf("申请成功\n");
 } 
 
 memset(p, 0, n * sizeof(int));//填充0 
 
 //查看 
    for (i = 0; i < n; i++)
        printf("%d ", p[i]);
    printf("\n");

    free(p);
    p = NULL;
    return 0;
}
```

以上代码中使用了 malloc 创建了一个由用户输入创建指定大小的内存，判断了内存地址是否创建成功，且使用了 memset 函数对该内存空间进行了填充值，随后使用 for 循环进行了查看。最后使用了 free 释放了内存，并且将 p 赋值 NULL，这点需要主要，不能使指针指向未知的地址，要置于 NULL；否则在之后的开发者会误以为是个正常的指针，就有可能再通过指针去访问一些操作，但是在这时该指针已经无用，指向的内存也不知此时被如何使用，这时若出现意外将会造成无法预估的后果，甚至导致系统崩溃，在 malloc 的使用中更需要需要。

### 2.2 内存泄漏与安全使用实例与讲解

内存泄漏是指在动态分配的内存中，并没有释放内存或者一些原因造成了内存无法释放，轻度则造成系统的内存资源浪费，严重的导致整个系统崩溃等情况的发生。

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6IbuENgx2gXpAD7hicysTdXkbtGibnDnicsloRCfHTUWpslPJicuH09RNYg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

内存泄漏通常比较隐蔽，且少量的内存泄漏发生不一定会发生无法承受的后果，但由于该错误的积累将会造成整体系统的性能下降或系统崩溃。特别是在较为大型的系统中，如何有效的防止内存泄漏等问题的出现变得尤为重要。例如一些长时间的程序，若在运行之初有少量的内存泄漏的问题产生可能并未呈现，但随着运行时间的增长、系统业务处理的增加将会累积出现内存泄漏这种情况；这时极大的会造成不可预知的后果，如整个系统的崩溃，造成的损失将会难以承受。由此防止内存泄漏对于底层开发人员来说尤为重要。

C 程序员在开发过程中，不可避免的面对内存操作的问题，特别是频繁的申请动态内存时会及其容易造成内存泄漏事故的发生。如申请了一块内存空间后，未初始化便读其中的内容、间接申请动态内存但并没有进行释放、释放完一块动态申请的内存后继续引用该内存内容；如上所述这种问题都是出现内存泄漏的原因，往往这些原因由于过于隐蔽在测试时不一定会完全清楚，将会导致在项目上线后的长时间运行下，导致灾难性的后果发生。

如下是一个在子函数中进行了内存空间的申请，但是并未对其进行释放：

```c
#include<stdio.h>
#include<string.h>
#include <malloc.h>
void m() { 
 char *p1; 
 p1 = malloc(100); 
 printf("开始对内存进行泄漏...");
}
 
int main() {
    m();
    return 0;
}
```

如上代码中，使用 malloc 申请了 100 个单位的内存空间后，并没有进行释放。假设该 m 函数在当前系统中调用频繁，那将会每次使用都将会造成 100 个单位的内存空间不会释放，久而久之就会造成严重的后果。理应在 p1 使用完毕后添加 free 进行释放：

```c
free(p1);
```

以下示范一个读取文件时不规范的操作：

```c
#include<stdio.h>
#include<string.h>
#include <malloc.h>
int m(char *filename) { 
 FILE* f;
 int key; 
 f = fopen(filename, "r"); 
 fscanf(f, "%d", &key); 
 return key; 
}
 
int main() {
    m("number.txt");
    return 0;
}
```

以上文件在读取时并没有进行 fclose，这时将会产生多余的内存，可能一次还好，多次会增加成倍的内存，可以使用循环进行调用，之后在任务管理器中可查看该程序运行时所占的内存大小，代码为：

```c
#include<stdio.h>
#include<string.h>
#include <malloc.h>
int m(char *filename) { 
 FILE* f;
 int key; 
 f = fopen(filename, "r"); 
 fscanf(f, "%d", &key); 
 return key; 
}
 
int main() {
 int i;
 for(i=0;i<500;i++) {
     m("number.txt");
 }
    return 0;
}
```

可查看添加循环后的程序与添加循环前的程序做内存占用的对比，就可以发现两者之间添加了循环的代码将会成本增加占用容量。

未被初始化的指针也会有可能造成内存泄漏的情况，因为指针未初始化所指向不可控，如：

```c
int *p;
*p = val;
```

包括错误的释放内存空间：

```c
pp=p;
free(p); 
free(pp);
```

释放后使用，产生悬空指针。在申请了动态内存后，使用指针指向了该内存，使用完毕后我们通过 free 函数释放了申请的内存，该内存将会允许其它程序进行申请；但是我们使用过后的动态内存指针依旧指向着该地址，假设其它程序下一秒申请了该区域内的内存地址，并且进行了操作。当我依旧使用已 free 释放后的指针进行下一步的操作时，或者所进行了一个计算，那么将会造成的结果天差地别，或者是其它灾难性后果。所以对于这些指针在生存期结束之后也要置为 null。查看一个示例，由于 free 释放后依旧使用该指针，造成的计算结果天差地别：

```c
#include<stdio.h>
#include<string.h>
#include <malloc.h>
int m(char *freep) { 
 int val=freep[0];
 printf("2*freep=:%d\n",val*2);
 free(freep);
 val=freep[0];
 printf("2*freep=:%d\n",val*2);
}
 
int main() {
 int *freep = (int *) malloc(sizeof (int));
 freep[0]=1;
 m(freep);
    return 0;
    
}
```

以上代码使用 malloc 申请了一个内存后，传值为 1；在函数中首先使用 val 值接收 freep 的值，将 val 乘 2，之后释放 free，重新赋值给 val，最后使用 val 再次乘 2，此时造成的结果出现了极大的改变，而且最恐怖的是该错误很难发现，隐蔽性很强，但是造成的后顾难以承受。运行结果如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/0m4YX595FokkU5AuuEtKdISfYw71AiaD6xBnKj1lr8TcYeHxfP7nurgIabTrCyepwvIL3KCyIbDlOx4ia2mNVnvg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 三、 new 和 delete

C++ 中使用 new 和 delete 从堆中分配和释放内存，new 和 delete 是运算符，不是函数，两者成对使用(后面说明为什么成对使用)。

new/delete 除了分配内存和释放内存（与 malloc/free），还做更多的事情，所有在 C++ 中不再使用 malloc/free 而使用 new/delete。

### 3.1 new 和 delete 使用

new 一般使用格式如下：

- 指针变量名 = new 类型标识符;
- 指针变量名 = new 类型标识符(初始值);
- 指针变量名 = new 类型标识符[内存单元个数];

在C++中new的三种用法包括：plain new， nothrow new 和 placement new。

plain new 就是我们最常使用的 new 的方式，在 C++ 中的定义如下：

```c
void* operator new(std::size_t) throw(std::bad_alloc);  
void operator delete( void *) throw();
```

plain new 在分配失败的情况下，抛出异常 std::bad_alloc 而不是返回 NULL，因此通过判断返回值是否为 NULL 是徒劳的。

```c
char *getMemory(unsigned long size)   
{    
    char * p = new char[size];   
    return p; 
}   
void main(void)   
{
    try{   
        char * p = getMemory(1000000);    // 可能发生异常
        // ...   
        delete [] p;   
    }   
    catch(const std::bad_alloc &amp; ex)   
    {
        cout &lt;&lt; ex.what();
    }   
}
```

nothrow new 是不抛出异常的运算符new的形式。nothrow new在失败时，返回NULL。定义如下：

```c
void * operator new(std::size_t, const std::nothrow_t&) throw();
void operator delete(void*) throw();
void func(unsinged long length)   
{
    unsinged char * p = new(nothrow) unsinged char[length];   
    // 在使用这种new时要加(nothrow) ，表示不使用异常处理 。
 
    if (p == NULL)  // 不抛异常，一定要检查
        cout << "allocte failed !";   
        // ...   
    delete [] p;
}
```

placement new 意即“放置”，这种new允许在一块已经分配成功的内存上重新构造对象或对象数组。placement new不用担心内存分配失败，因为它根本不分配内存，它做的唯一一件事情就是调用对象的构造函数。定义如下：

```c
void* operator new(size_t, void*);
void operator delete(void*, void*);
```

palcement new 的主要用途就是反复使用一块较大的动态分配的内存来构造不同类型的对象或者他们的数组。placement new构造起来的对象或其数组，要显示的调用他们的析构函数来销毁，千万不要使用delete。

```c
void main()   
{  
    using namespace std;   
    char * p = new(nothrow) char [4];   
    if (p == NULL)   
    {
        cout << "allocte failed" << endl;  
        exit( -1 );
    }   
    // ...   
    long * q = new (p) long(1000);   
    delete []p;    // 只释放 p，不要用q释放。
}
```

p 和 q 仅仅是首址相同，所构建的对象可以类型不同。所“放置”的空间应小于原空间，以防不测。当”放置new”超过了申请的范围，Debug 版下会崩溃，但 Release 能运行而不会出现崩溃！

该运算符的作用是：只要第一次分配成功，不再担心分配失败。

```c
void main()   
{
    using namespace std;   
    char * p = new(nothrow) char [100];   
    if (p == NULL)   
    {  
        cout << "allocte failed" << endl;
        exit(-1);
    }   
    long * q1 = new (p) long(100);   
    // 使用q1  ...   
    int * q2 = new (p) int[100/sizeof(int)];   
    // 使用q2 ...   
    ADT * q3 = new (p) ADT[100/sizeof(ADT)];   
    // 使用q3  然后释放对象 ...   
    delete [] p;    // 只释放空间，不再析构对象。
}
```

注意：使用该运算符构造的对象或数组，一定要显式调用析构函数，不可用 delete 代替析构，因为 placement new 的对象的大小不再与原空间相同。

```c
void main()   
{  
    using namespace std;   
    char * p = new(nothrow) char [sizeof(ADT)+2];   
    if (p == NULL)   
    {  
        cout << "allocte failed" &lt;&lt; endl;
        exit(-1); 
    } 
    // ... 
    ADT * q = new (p) ADT; 
    // ... 
    // delete q; // 错误
    q->ADT::~ADT();  // 显式调用析构函数，仅释放对象
    delete [] p;     // 最后，再用原指针来释放内存
}
```

placement new 的主要用途就是可以反复使用一块已申请成功的内存空间。这样可以避免申请失败的徒劳，又可以避免使用后的释放。

特别要注意的是对于 placement new 绝不可以调用的 delete, 因为该 new 只是使用别人替它申请的地方。释放内存是 nothrow new 的事，即要使用原来的指针释放内存。free/delete 不要重复调用，被系统立即回收后再利用，再一次 free/delete 很可能把不是自己的内存释放掉，导致异常甚至崩溃。

上面提到 new/delete 比 malloc/free 多做了一些事情，new 相对于 malloc 会额外的做一些初始化工作，delete 相对于 free 多做一些清理工作。

```c
class A
{
 public:
     A()
     {
        cont<<"A()构造函数被调用"<<endl;
     }
     ~A()
     {
        cont<<"~A()构造函数被调用"<<endl;
     }
}
```

在 main 主函数中，加入如下代码：

```c
A* pa = new A();  //类 A 的构造函数被调用
delete pa;        //类 A 的析构函数被调用
```

可以看出：使用 new 生成一个类对象时系统会调用该类的构造函数，使用 delete 删除一个类对象时，系统会调用该类的析构函数。可以调用构造函数/析构函数就意味着 new 和 delete 具备针对堆所分配的内存进行初始化和释放的能力，而 malloc 和 free 不具备。

### 2.2 delete 与 delete[] 的区别

c++ 中对 new 申请的内存的释放方式有 delete 和 delete[] 两种方式，到底这两者有什么区别呢？

我们通常从教科书上看到这样的说明：

- delete 释放 new 分配的单个对象指针指向的内存
- delete[] 释放 new 分配的对象数组指针指向的内存 那么，按照教科书的理解，我们看下下面的代码：

```c
int *a = new int[10];
delete a;        //方式1
delete[] a;     //方式2
```

1. 针对简单类型 使用 new 分配后的不管是数组还是非数组形式内存空间用两种方式均可 如：

```c
int *a = new int[10];
delete a;
delete[] a;
```

此种情况中的释放效果相同，原因在于：分配简单类型内存时，内存大小已经确定，系统可以记忆并且进行管理，在析构时，系统并不会调用析构函数。

它直接通过指针可以获取实际分配的内存空间，哪怕是一个数组内存空间(在分配过程中 系统会记录分配内存的大小等信息，此信息保存在结构体 _CrtMemBlockHeader 中，具体情况可参看 VC 安装目录下 CRTSRCDBGDEL.cpp)。

1. 针对类 Class，两种方式体现出具体差异

当你通过下列方式分配一个类对象数组：

```c
class A
   {
    private:
      char *m_cBuffer;
      int m_nLen;

   `` public:
      A(){ m_cBuffer = new char[m_nLen]; }
      ~A() { delete [] m_cBuffer; }
   };

   A *a = new A[10];
   delete a;         //仅释放了a指针指向的全部内存空间 但是只调用了a[0]对象的析构函数 剩下的从a[1]到a[9]这9个用户自行分配的m_cBuffer对应内存空间将不能释放 从而造成内存泄漏
   delete[] a;      //调用使用类对象的析构函数释放用户自己分配内存空间并且   释放了a指针指向的全部内存空间
```

所以总结下就是，如果 ptr 代表一个用new申请的内存返回的内存空间地址，即所谓的指针，那么：

delete ptr  代表用来释放内存，且只用来释放 ptr 指向的内存。delete[] rg  用来释放rg指向的内存，！！还逐一调用数组中每个对象的destructor！！

对于像 int/char/long/int*/struct 等等简单数据类型，由于对象没有 destructor ，所以用 delete 和 delete []是一样的！但是如果是 C++ 对象数组就不同了！

关于 new[] 和 delete[]，其中又分为两种情况：

- (1) 为基本数据类型分配和回收空间；
- (2) 为自定义类型分配和回收空间；

对于 (1)，上面提供的程序已经证明了 delete[] 和 delete 是等同的。但是对于 (2)，情况就发生了变化。

我们来看下面的例子，通过例子的学习了解 C++ 中的 delete 和 delete[] 的使用方法

```c
#include <iostream>
using namespace std;

class Babe
{
public:
    Babe()
    {
        cout << \"Create a Babe to talk with me\" << endl;
    }

    ~Babe()
    {
        cout << \"Babe don\'t Go away,listen to me\" << endl;
    }
};

int main()
{
    Babe* pbabe = new Babe[3];
    delete pbabe;
    pbabe = new Babe[3];
    delete[] pbabe;
    return 0;
}
```

结果是:

```c
Create a babe to talk with me
Create a babe to talk with me
Create a babe to talk with me
Babe don\'t go away,listen to me
Create a babe to talk with me
Create a babe to talk with me
Create a babe to talk with me
Babe don\'t go away,listen to me
Babe don\'t go away,listen to me
Babe don\'t go away,listen to me
```

大家都看到了，只使用 delete 的时候只出现一个 `Babe don’t go away,listen to me`，而使用 delete[] 的时候出现 3 个 `Babe don’t go away,listen to me`。不过不管使用 delete 还是 delete[] 那三个对象的在内存中都被删除，既存储位置都标记为可写，但是使用 delete 的时候只调用了 pbabe[0] 的析构函数，而使用了 delete[] 则调用了 3 个 Babe 对象的析构函数。

你一定会问，反正不管怎样都是把存储空间释放了，有什么区别。

答：关键在于调用析构函数上。此程序的类没有使用操作系统的系统资源（比如：Socket、File、Thread等），所以不会造成明显恶果。如果你的类使用了操作系统资源，单纯把类的对象从内存中删除是不妥当的，因为没有调用对象的析构函数会导致系统资源不被释放，这些资源的释放必须依靠这些类的析构函数。所以，在用这些类生成对象数组的时候，用 delete[] 来释放它们才是王道。而用 delete 来释放也许不会出问题，也许后果很严重，具体要看类的代码了。



# [char *str与char str[]的区别](https://mp.weixin.qq.com/s?__biz=MzU5MzcyMjI4MA==&mid=2247483862&idx=2&sn=cef070d13684fa68f466a93ff17ab0c0&chksm=fe0d6f11c97ae607db0086f6bdc8b89fc54be7c331c99118c982c47db70ed7cf6011e95ae106&mpshare=1&scene=1&srcid=0616D5xZbdWjjdLggo2RMLE7&sharer_sharetime=1623844586423&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)

C语言中没有特定的字符串类型，常用以下两种方式定义字符串：一种是字符数组，另一种是指向字符串的指针。如下：

(1)char str[] = "happy";

(2)char *str = "happy";

这种方式有什么不同呢？

下面看两个例子：修改字符串中的字符



示例1：

```
#include <stdio.h>

int main(void)
{
 char str[20] = "hello";
 
 str[0] = 'H';
 printf("%s\n",str);
 
 return 0;
}
```



运行结果：

> Hello



示例2：

```
#include <stdio.h>

int main(void)
{
 char *str = "hello";
 
 str[0] = 'H';
 printf("%s\n",str);
 
 return 0;
}
```



运行结果：

> 无打印信息输出



可见，使用（1）方式定义的字符串其字符是可以修改的，使用（2）方式定义的字符串其字符是不可以修改的。（2）中可以成功编译和链接，但运行时可能会出现错误，我编译与运行的平台是window10平台，运行结果是无打印信息输出，在其他不同的平台运行可能会出现段错误（Segment Fault）或者写入位置错误。



这两种表示字符串的方式的主要区别是：**字符串指针指向的内容是不可修改的，字符数组是可以修改的**，即（2）方式定义的字符串保存在**常量区**，是不可更改的，（1）方式定义的字符串保存在**全局数据区或栈区**，是可修改的。



**内存的分配方式：**

内存分配可分为三种：静态存储区、栈区、堆区。

1、静态存储区：该内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在，它主要存放静态数据、全局数据和常量。



2、栈区：它的用途是完成函数的调用。在执行函数时，函数内局部变量及函数参数的存储单元在栈上创建，函数调用结束时这些存储单元自动被释放。



3、堆区：程序在运行时使用库函数为变量申请内存，在变量使用结束后再调用库函数释放内存。动态内存的生存期是由我们决定的，如果我们不释放内存，就会导致内存泄漏。



# [一份通俗易懂的C语言内存总结](https://mp.weixin.qq.com/s?__biz=MzU5MzcyMjI4MA==&mid=2247483844&idx=2&sn=721c98390ec70fec0fe6c46823c928bc&chksm=fe0d6f03c97ae615311d38d3535d42de347b7dfc4ab8b846707a600450c0b82f784c0562ee75&scene=21#wechat_redirect)



C语言程序需要载入内存才可以运行，其不同的数据保存在不同的区域。所使用的内存可以分成两类：一类是静态存储区，另一类是动态存储区。C语言程序的存储区如下图所示：



![图片](https://mmbiz.qpic.cn/mmbiz_jpg/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGdLyUlwAI4EJZTrnTiaCwhEia5VpOcez5Diawfs8r5qqMltxEOCotCu82A/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



**1静态存储区**

静态存储区分为三类：**只读数据区（RO Data）**、**已初始化读写数据区（RW Data）**、**未初始化读写读写数据区（BSS）**。这三类存储区都是在程序的编译-连接阶段确定的，且运行过程中是不会变化的，只有当程序退出的时候，静态存储区的内存才会被系统回收。



**2动态存储区**

动态存储区主要分为两类：一类是**栈（Stack）内存区域**，栈内存是由编译器管理的；另一类是**堆（Heap）内存区域**，堆内存由程序调用具体的库函数来分配的。它们都是程序运行过程中动态分配的。

**2.1栈内存区域**

**2.1.1栈的相关概念**

栈内存的使用很大的程度上依赖于处理器的硬件机制。在处理器中，有一个寄存器来表示当前栈指针的位置。通常在内存中分配一块区域，这块区域的上界（高内存地址）和下界（低内存地址）之间是可用的栈内存区域。栈内存如下图所示：

 

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGdLyUlwAI4EJZTrnTiaCwhEia5VpOcez5Diawfs8r5qqMltxEOCotCu82A/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



目前常见的体系结构和编译系统中，栈大多都是向下增长的。在初始阶段，栈指针是指向栈区间的上界，随着栈使用量的增加，栈指针的值向低地址移动，即栈指针的值将变小。下面来看一段程序：

```c
#include <stdio.h>

int main(void)
{
 int a = 1, b = 2, c = 3;
 
 printf("a = %d, &a = %#x \n", a, (unsigned int)&a);
 printf("b = %d, &b = %#x \n", b, (unsigned int)&b);
 printf("c = %d, &c = %#x \n", c, (unsigned int)&c);
 
 return 0;
}
```

程序运行结果为：



![图片](https://mmbiz.qpic.cn/mmbiz_png/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGELiavU2JC1HjsibibW5UKjmTibNtLnHZx9Kfx5VsEnkVCB1J289se2MCvg/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



可见，变量的存储是从高地址往低地址的方向存储。

栈有一个重要的特性：先放入的数据最后才能取出，后放入的数据优先能取出，即**先进后出（First In Last Out）**原则。放入数据常被称为入栈或压栈（Push），取出数据被称为出栈或弹出（Pop）。在运用过程中，栈内存可能出现满栈和空栈两种情况，这是由处理器的体系结构决定的。

栈（Stack）可以存放函数参数、局部变量、局部数组等作用范围在函数内部的数据，它的用途就是**完成函数的调用**。



**2.1.1需要知道的关于栈的问题：**

（1）函数在调用完成之后，栈指针将回到函数进入之前的位置。下面的程序通过两次调用同一个函数印证了这一点：

```c
#include <stdio.h>

void stack_test1(int a, int b, int c);

int main(void)
{
 int a = 1, b = 2, c = 3;
 int a1 = 4, b1 = 5, c1 = 6;
 
 printf("第一次调用stack_test1函数：\n");
 stack_test1(a, b, c);
 printf("第二次调用stack_test1函数：\n");
 stack_test1(a1, b1, c1);
 
 return 0;
}

void stack_test1(int a, int b, int c)
{
 printf("a = %d, &a = %#x \n", a, (unsigned int)&a);
 printf("b = %d, &b = %#x \n", b, (unsigned int)&b);
 printf("c = %d, &c = %#x \n", c, (unsigned int)&c);
}
```

程序运行结果：



![图片](https://mmbiz.qpic.cn/mmbiz_png/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGx75IXLJVftSfJ3z7FMazYYnoA94XHSRutia2ZAjrkBCnib7z6DWwhcOQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



可见，两次调用中函数参数使用的栈内存是相同的，即第一次调用函数完成之后，栈指针将回到函数进入之前的位置。



（2）在函数调用的过程中，每增加一个层次，栈空间就会被压入更多的内容，下面的程序验证了这一点：

```c
#include <stdio.h>
#include <stdlib.h>
void stack_test1(int a, int b, int c);
void stack_test2(int a, int b, int c);

int main(void)
{
 int a = 1, b = 2, c = 3;
 
 printf("直接调用stack_test1函数：\n");
 stack_test1(a, b, c);
 printf("通过stack_test2函数间接调用stack_test1函数：\n");
 stack_test2(a, b, c);
 
 return 0;
}

void stack_test1(int a, int b, int c)
{
 printf("a = %d, &a = %#x \n", a, (unsigned int)&a);
 printf("b = %d, &b = %#x \n", b, (unsigned int)&b);
 printf("c = %d, &c = %#x \n", c, (unsigned int)&c);
}

void stack_test2(int a, int b, int c)
{
 stack_test1(a, b, c);
}
```

程序运行结果：



![图片](https://mmbiz.qpic.cn/mmbiz_png/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGicibBKdOthEMGf1YCYdxcicCkWze2fqQF4tJ3RNkL63UYeAwqQnRs6szg/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



可见，在程序中两次调用stack_test1函数，第一次是直接调用，第二次是通过stack_test2函数间接调用。从运行结果来看，通过stack_test2函数间接调用stack_test1函数的栈指针的值变小了，说明是由于栈中压入了更多的内容。



（3）函数调用结束后，函数栈上的内容不能被其他函数使用。例如，下面是一种错误的用法：

```c
int *stack_test3(void)
{
 int a;
 /* ...... */
 return (&a);
}
```

return(&a)将自动变量a的值返回，这种写法不会发生编译错误（又可能出现警告），但是其逻辑是不正确的。此时，调用者可以得到stack_test3运行时a的地址，但是由于变量a是建立在栈上，函数退出后，栈区域已经释放，这个地址已经指向无效的内存，因此不应该再被程序使用。

**
**

**2.2堆内存区域**

**2.2.1堆的相关概念**

在一般的编译系统中，堆内存的分配方向和栈内存是相反的。栈内存利用的是处理器的硬件机制，而堆内存的处理使用的是库函数。堆内存的分配形式如下图：



![图片](https://mmbiz.qpic.cn/mmbiz_png/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGr04K2bAcqgfAJK566DxPaQZkDgpeicXRmsUwYB9H11HicBud3iaco9PxA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



可见，堆内存与栈内存的区别：栈内存只有一个入口点，就是栈指针，栈内存压栈和出栈都只能通过栈指针及其偏移量；而堆内存有多个入口点，每次分配得到的指针就是访问内存的入口，每个分配内存区域都可以被单独释放。

当频繁的分配和释放内存的过程中，将会出现如下情况：在两块已经分配的内存之间可能出现较小的未分配的内存区域，这些内存理论上可以被使用。但是由于它们的空间较小，不够连续内存的分配，因此当分配内存的时候，它们经常不能被使用。这种较小的内存就是内存碎片。



**2.2.2关于堆空间的使用及其一些问题：**

（1）库文件：stdlib.h

实现堆内存分配和释放的4个主要函数为：

```c
/* 分配内存空间 */
void *malloc(size_t size);
/* 释放内存空间 */
void free(void *ptr);
/* 分配内存空间 */
void *calloc(size_t num, size_t size);
/* 重新分配内存空间 */
void *realloc(void *ptr, size_t size);
```



（2）malloc和free的简单应用

```c
//malloc和free的简单应用
void heap_test1(void)
{
 int *pa;
 
 pa = (int*)malloc(sizeof(int));
 if ( NULL != pa )
 {
   *pa = 0x1234;
   printf("pa = %#x, *pa = %x\n", (unsigned int)pa, *pa);
   free(pa);
 }
 
 return;
}
```

在malloc分配完内存之后，可以用得到的指针值是否为NULL来判断内存是否分配成功。按照C语言内存分配规则，如果内存分配成功，返回的是内存的地址；如果内存分配不成功，将返回NULL（0x0），表示一个无效的地址。



（3）malloc在分配内存的时候，是从低地址至高地址方向。但是，先分配的内存地址不一定比后分配的内存地址小。下面的程序验证了这一点：

```c
//后分配内存地址反而更小
void heap_test2(void)
{
 void *pa;
 void *pb;
 void *pc;
 void *pd;
 pa = (int*)malloc(1024);
 printf("pa = %#x \n", (unsigned int)pa);
 pb = (int*)malloc(1024);
 printf("pb = %#x \n", (unsigned int)pb);
 pc = (int*)malloc(1024);
 printf("pc = %#x \n", (unsigned int)pc);
 free(pb);
 pd = (int*)malloc(1024);
 printf("pd = %#x \n", (unsigned int)pd);

 free(pa);
 free(pc);
 free(pd);
 
 return;
}
```

程序运行结果：



![图片](https://mmbiz.qpic.cn/mmbiz_png/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGMiaQfic5yZlibEtibtp08VDUSaf7owjyyPzPzmBL3bXMELLJKpkOsstLGw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



可见，在该程序中，首先3次分配1024字节的堆上内存，然后再将第二次分配的内存释放，再次分配内存时，将利用了这一块空间。

（4）calloc()和malloc()很类似，主要区别是calloc()可以将分配好的内存区域的初始值全部设置为0，以下程序验证了这一点：

```c
//calloc和malloc的主要区别
void heap_test3(void)
{
 unsigned int *pa;
 int i;
 
 pa = (unsigned int*)calloc(sizeof(unsigned int), 5);
 if ( NULL != pa )
 {
   printf("<< colloc pa = %#x >>\n", (unsigned int)pa);
   for ( i = 0; i < 5; i++ )
   {
     printf("pa[%d] = %d \n", i, pa[i]);
   }
   free(pa);
 }
 
 return;
}
```

程序运行结果：



![图片](https://mmbiz.qpic.cn/mmbiz_png/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGhohEyLz68IWGB60TtAtOX6piaPlQCEtiastOYQTEAA9qGH4MibPl87NEQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



除此之外，calloc()和malloc()另外一个不同之处在于参数的个数，malloc只有一个参数，即要分配的内存字节数；calloc有两个参数，第一个是分配单元的大小，第二个是要分配的数目。从本质上，calloc使用两个参数和malloc使用一个并没有区别。



（5）realloc的应用。realloc函数具有两个参数，一个是指向内存的地址指针，另一个是重新分配内存的大小，而返回值是指向所分配内存的指针。基本应用代码如下：

```c
//realloc的应用
void heap_test4(void)
{
 int *pa;
 int i;
 
 pa = (int*)malloc(sizeof(int)*6);
 if ( NULL != pa ){
   for ( i = 0; i < 6; i++ ){
     *(pa + i) = i;
   }
   for ( i = 0; i < 6; i++ ){
     printf("pa[%d] = %d \n", i, pa[i]);
   }
 }
 printf("relloc重新分配内存\n");
 pa = (int*)realloc(pa, sizeof(int)*10);
 if ( NULL != pa ){
   for ( i = 0; i < 10; i++ ){
     printf("pa[%d] = %d\n", i, pa[i]);
   }
   free(pa);
 }
 
 return;
}
```

程序运行结果：

 

![图片](https://mmbiz.qpic.cn/mmbiz_png/PnO7BjBKUz9zPUvdbspFcgrGyCbicZgmGKQGmCMG2PXzjKYn1go2UgGc87Lho3JMxJ9fOfAV5GsMq4zeA9Va6ew/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



除此之外，realloc还具有两种功能：一是当指针为NULL的时候，作为malloc使用，分配内存；二是当重新分配内存大小为0的时候，作为free使用，释放内存。



（6）再堆内存的管理上，容易出现以下几个问题：

- 开辟的内存没有释放，造成内存泄漏

内存泄漏的例子：

```c
//内存泄漏例子
void heap_test6(void)
{
 char *pa;
 pa = (char*)malloc(sizeof(char)*20);
 /* ...... */
 
 return;
}
```



在函数heap_test6中，使用malloc开辟了20个字节的内存区域，但是使用结束后该函数没有释放这块区域，也没有通过任何返回值或者参数的手段将这块内存区域的地址告诉其它函数。此时，这20个字节的内存不会被任何程序释放，因此再调用该函数的时候，就会导致内存泄漏。



- 野指针被使用或者释放

野指针是一个已经被释放的内存指针，它指向的位置已经被free或者realloc释放了，此时再使用该指针，就会导致程序的错误。野指针例子：

```c
//野指针例子
void heap_test6(void)
{
 char *pa;
 pa = (char*)malloc(sizeof(char)*20);
 /* ...... */
 free(pa);
 /* ...... */
 printf("pa = %s \n",pa); //野指针被使用
 
 return;
}
```



在此程序中，调用free函数已经释放了pa指针，但后面还在继续使用pa，这就是一个错误的程序。

- 非法释放指针

1）	非法释放静态存储区的内存，示例如下：

```c
//非法释放静态存储区的内存
void heap_test7(void)
{
 /* ...... */
 /* 错误释放只读数据区指针 */
 free(ro_data);
 /* 错误释放已初始化读写数据区指针 */
 free(rw_data);
 /* 错误释放未初始化读写数据区指针 */
 free(bss_data);
 
 /* 错误释放代码区指针 */
 free(heap_test7);
 /* ...... */
 return;
}
```



2）	非法释放栈上的内存，示例如下：

```c
//非法释放栈上的内存
void heap_test8(void)
{
 char a[20];
 int b;
 
 /* 错误释放栈上内存 */
 
 /* ...... */
 free(a);
 free(&b);
 /* ...... */
 return;
}
```



3）	非法释放堆上内存，示例如下：

```c
//非法释放堆上的内存---1
void heap_test9(void)
{
 char *pa;
 /* ...... */
 pa = (char*)malloc(sizeof(char)*20);
 free(pa);
 free(pa);  //错误释放堆内存
 /* ...... */
 return;
}
```

第一次释放之后，该地址已经变成了未被分配的堆上的内存了，free函数不能释放未分配的堆内存。



```c
//非法释放堆上的内存---2
void heap_test10(void)
{
 char *pa;
 char *pb;
 /* ...... */
 pa = (char*)malloc(sizeof(char)*20);
 pb = pa++;
 free(pb);  //错误释放堆内存
 /* ...... */
 return;
}
```

释放内存pb是非法的内存释放，由于这个指针并不是从malloc分配出来的，而是一个中间的指针值。



# [C 语言内存分配](https://mp.weixin.qq.com/s?__biz=MzA5NTM3MjIxMw==&mid=2247484868&idx=1&sn=9b7c9db562fef3ecb1ac6c6380de2bde&chksm=9041131ea7369a08885289c104e4a53ea14709e4e4c5defdc740fe15c31ac2fc196358e502ec&mpshare=1&scene=24&srcid=0616tLB1MSYWHRzKLrVqFJqk&sharer_sharetime=1623843744845&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)

C 语言内存分配的框图如下，一个正常的执行代码， 操作系统需要给他分配一段内存区域，这一大块内存区域还要分为几个小区域。



1.文本段（Text segment）

2.初始化数据段（Initialized data segment）

3.未初始化数据段（Uninitialized data segment）

4.堆栈（Stack）

5.堆 （Heap）

![图片](https://mmbiz.qpic.cn/mmbiz_png/Qof5hj3zMPek86vka2NSz0SCAibwIR0UGucs6pFr935DERQWNmiavKWqjfMho3KMmKWvSj8sd4vtjJfnDVXFibkvA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





**1.文本段：**
文本段，也称为代码段，是目标文件或内存中包含可执行指令的程序的一部分。作为存储区域，文本段可以放置在堆或堆栈下方，以防止堆和堆栈溢出覆盖它。通常，文本段是可共享的，因此对于频繁执行的程序（例如文本编辑器，C 编译器，shell 等），只需要一个副本就可以在内存中。此外，文本段通常是只读的，以防止程序意外修改其指令。文本段可以看做 这段代码 的 大脑，需要怎么执行，做什么，都把数据保存在这个位置了。



**2.初始化数据段：**
初始化数据段，通常简称为数据段。数据段是程序的虚拟地址空间的一部分，其包含由程序员初始化的全局变量和静态变量。

请注意，数据段不是只读的，因为变量的值可以在运行时更改。

该段可以进一步分类为**初始化的只读区域**和**初始化的读写区域**。

例如，C 中的 char s [] =“hello world”定义的全局字符串，和 int debug = 1 之类的 C语句 将存储在初始化的**读写区域**中。像 const char * string =“hello world”这样的全局 C语句 会把 字符串文字“hello world”存储在初始化的**只读区域**中，而字符指针变量字符串存储在初始化的读写区域中。

例如：static int i = 10 将存储在数据段中，global int i = 10 也将存储在数据段中

**3.未初始化的数据段：**

未初始化的数据段，通常称为**“bss”段**，以古代汇编运算符命名，代表“由符号启动的块”。此段中的数据在程序启动之前由内核初始化为算术 0 执行

未初始化的数据从数据段的末尾开始，包含初始化为零或在源代码中没有显式初始化的**所有全局变量和静态变量**。

例如，变量声明为static int i; 将包含在BSS部分中。
例如，一个声明为int j的全局变量; 将包含在BSS部分中。

**4.堆栈：**

我们很多时候说的堆栈，实际上就是栈（ stack ）跟堆（ heap ）是没有关系的。我们学习上经常说的 压栈，说的就是压堆栈，因为堆栈有 「先进后出的原则」，所以我们操作的是栈尾。

堆栈区域传统上与堆区域相邻并向相反方向增长; 当堆栈指针遇到堆指针时，可用内存耗尽（因为理论上这个两个家伙是不可能 相遇的） 。（使用现代大地址空间和虚拟内存技术，它们几乎可以放置在任何地方，但它们通常仍会朝着相反的方向发展。）

堆栈区域包含程序堆栈，LIFO结构，通常位于存储器的较高部分。在标准的PC x86计算机体系结构上，它向零地址发展; 在其他一些架构上，它朝着相反的方向发展。“堆栈指针”寄存器跟踪堆栈的顶部; 每次将值“推”到堆栈上时都会调整它。

**5.堆：**
堆是通常发生动态内存分配的段。

堆区域从BSS 段的末尾开始，并从那里增长到更大的地址。堆区域由 malloc，realloc 和 free 管理，可以使用 brk 和 sbrk 系统调用来调整其大小;它们也可以使用mmap实现，将不连续的虚拟内存区域保留到进程的“虚拟地址空间”中。堆区域由进程中的所有共享库和动态加载的模块共享。



实用 size 命令可以分析生成的可执行程序每个段的大小，单位是（bytes 字节）。我们可以用这个命令验证上面的论证。

代码实例

```c
#include<stdio.h>

int main()
{
    return 0;
}
Linux@dev:~/cStudy$ gcc memory-test.c -o memory-test && size memory-test
   text    data     bss     dec     hex filename
   1099     544       8    1651     673 memory-test
Linux@dev:~/cStudy$ 
```

现在代码里面什么都没有，可以看到每个段内容的大小。

```c
#include<stdio.h>

int g;

int main()
{
    static int i;
    return 0;
}
--------------------------------------------------
Linux@dev:~/cStudy$ gcc memory-test.c -o memory-test && size memory-test
   text    data     bss     dec     hex filename
   1099     544      16    1659     67b memory-test
Linux@dev:~/cStudy$ 
```

我们声明了一个未初始化的全局变量和一个未初始化的静态变量后，bss 段发生了变化。



再修改一下

```c
#include<stdio.h>

int g = 99;

int main()
{
    static int i = 100;
    return 0;
}
--------------------------------------------------
Linux@dev:~/cStudy$ gcc memory-test.c -o memory-test && size memory-test
   text    data     bss     dec     hex filename
   1099     552      8     1659     67b memory-test
Linux@dev:~/cStudy$ 
```

初始化后 bss 段变成原来 8 了， data 段多了 8 个字节。

再修改一下

```c
#include<stdio.h>

int g ;

int main()
{
    static int i = 100;
    return 0;
}
--------------------------------------------------
Linux@dev:~/cStudy$ gcc memory-test.c -o memory-test && size memory-test
   text    data     bss     dec     hex filename
   1099     548      12     1659     67b memory-test
Linux@dev:~/cStudy$ 
```

这样 bss 段和 data 段都比初始值增加了 4 个字节。



推荐之前跟这个相关的文章，也是写 内存 区域的东西，两篇文章联系起来看会非常好。

[堆和栈的区别（转过无数次的文章）](http://mp.weixin.qq.com/s?__biz=MzA5NTM3MjIxMw==&mid=2247484507&idx=1&sn=f87570b981050ae6bc1e59967fdbddcd&chksm=90411281a7369b973f2d7e347d24aaed6d9dbba7ed380dde7e55de7cbb0cb088f2617c9bd792&scene=21#wechat_redirect)



还是推荐一下我的知识星球，加入星球的福利我会慢慢增加，当然还是以自愿为主，加入星球了同学，希望还是在星球提问题，这样的问答环境会更好，也方便追溯问题。

[我的知识小密圈](http://mp.weixin.qq.com/s?__biz=MzA5NTM3MjIxMw==&mid=2247484790&idx=1&sn=972d875063a6585d38f923f9ef491e85&chksm=904113aca7369aba2cdc63cfa9e7545975a29b2177f127956b9ce0b1b62d14348fc192bed035&scene=21#wechat_redirect)



昨天大概看了一下文章的情况，发现收藏的人数很多，但是转发的人数很少，各位大哥哥，大帅哥，能不能给小弟一点点活路稍微转发一下，在知乎的时候，就是收藏的数量远远超过点赞，已经让我很伤心了。

# [数组与指针有哪些区别？](https://mp.weixin.qq.com/s?__biz=MzU5MzcyMjI4MA==&mid=2247485580&idx=1&sn=c18c0dee9ad0e47d009afa702843d3d0&chksm=fe0d664bc97aef5db4e0a7ee4d51576e158cb01fe7fe5d475c44b19bb41909ef9c44501c033e&mpshare=1&scene=24&srcid=0616HyiS0B4WmMyyVD8TCJk3&sharer_sharetime=1623852503691&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)

## 前言 

数组与指针是不等价的，如：

- 数组名不可以改变，而指向数组的指针是可以改变的。
- 字符串指针指向的字符串中的字符是不能改变的，而字符数组中的字符是可以改变的。
- 求数组长度时，借用数组名可求得数组长度，而借用指针却得不到数组长度。

## 区别一

数组名的指向不可以改变，而指向数组的指针是可以改变的。

请看如下代码：

```c
#include <stdio.h>

int main(void)
{
 int a[5] = {0, 1, 2, 3, 4}, *p = a;
 char i;
 
 // 数组遍历方式一
 for ( i = 0; i < 5; i++ )
 {
   printf("a[%d] = %d\n", i, *p++);
 }
 
 // 数组遍历方式二
 for ( i = 0; i < 5; i++ )
 {
   printf("a[%d] = %d\n", i, *a++);
 }
 
 return0;
}
```

数组遍历方式一：使用指针遍历数组元素，*p++等价于*(p++)，即指针指向的地址每次后移一个单位，然后再取地址上的值。这里的一个单位是sizeof(int)个字节。

数组遍历方式二：使用数组名自增遍历数组元素，编译出错，错误如下：

```c
error: value required as increment operand
```

因为数组名的指向是不可以改变的，使用自增运算符自增就会改变其指向，这是不对的，数组名只能指向数组的开头。但是可以改为如下遍历方式：

```c
for ( i = 0; i < 5; i++ )
 {
   printf("a[%d] = %d\n", i, *(a+i));
 }
```

这可以正确遍历数组元素。因为*(a+i)与a[i]是等价的。

## 区别二

字符串指针指向的字符串中的字符是不能改变的，而字符数组中的字符是可以改变的。

请看如下代码：

```c
//字符串定义方式一
char str[] = "happy";

//字符串定义方式二
char *str = "happy";
```

字符串定义方式一：字符串中的字符是可以改变的。如可以使用类似str[3]='q'这样的语句来改变其中的字符。原因就是：这种方式定义的字符串保存在全局数据区或栈区，是可读写的。

字符串定义方式二：字符串中的字符是不可以改变的。原因就是：这种方式定义的字符串保存在常量区，是不可修改的。

## 区别三

求数组长度时，借用数组名可求得数组长度，而借用指针却得不到数组长度。

请看如下代码：

```c
#include <stdio.h>

int main(void)
{
 int a[] = {0, 1, 2, 3, 4}, *p = a;
 char len = 0;
 
 // 求数组长度方式一
 printf("方式一：len=%d\n",sizeof(a)/sizeof(int));
 
 // 求数组长度方式二
 printf("方式二：len=%d\n",sizeof(p)/sizeof(int));
 
 return0;
}
```

运行结果

```c
方式一：len=5
方式二：len=1
```

求数组长度方式一：借用数组名来求数组长度，可求得数组有5个元素，正确。

求数组长度方式二：借用指针求数组长度，求得长度为1，错误。原因是：

p只是一个指向int类型的指针，编译器不知道其指向的是一个整数还是指向一个数组。sizeof(p)求得的是p这个指针变量本身所占用的字节数，而不是整个数组占用的字节数。

以上就是指针与其指向的数组的三个典型的区别：（1）遍历数组时需要注意；（2）修改字符串中的字符时需要注意；（3）求数组长度时需要注意。





# [C语言：什么是野指针和内存泄漏？如何避免野指针](https://mp.weixin.qq.com/s?__biz=MzIzNjgxNjA3MQ==&mid=2247484911&idx=1&sn=367cfee69fa10d5f14fd01011fe5c4a3&chksm=e8d35647dfa4df516ce2ac4981b9c568fbfd9e95afdcaf13105e4e628394255fd6012f46bd78&scene=0&xtrack=1#rd)

## 内存泄漏：

①访问已经释放的内存

②访问没有权限的内存

## 野指针：

指向内存被释放的内存或者没有访问权限的内存的指针。

“野指针”的成因主要有3种：

（1）指针变量没有被初始化。任何指针变量刚被创建时不会自动成为NULL指针，它的缺省值是随机的，它会乱指一气。所以，指针变量在创建的同时应当被初始化，要么将指针设置为NULL，要么让它指向合法的内存。例如

char *p = NULL;

char *str = new char(100);

（2）指针p被free或者delete之后，没有置为NULL。

（3）指针操作超越了变量的作用范围。这种情况让人防不胜防，示例程序如下：

```c
class A 
{ 
 public:
void Func(void){ cout << “Func of class A” << endl; }
};
void Test(void)
{
 A *p;
 if(...)
 {
A a;
p = &a; // 注意 a 的生命期
 }
 p->Func(); // p是“野指针”
}
```

## 如何避免野指针：

一、对指针进行初始化

①将指针初始化为NULL。

char * p = NULL;

②用malloc分配内存

```c
char * p = (char * )malloc(sizeof(char));
```

③用已有合法的可访问的内存地址对指针初始化

```c
char num[ 30] = {0};
char *p = num;
```

二、指针用完后释放内存，将指针赋NULL。

```c
delete(p);
p = NULL;
```

注：

malloc函数分配完内存后需注意：

①检查是否分配成功（若分配成功，返回内存的首地址；分配不成功，返回NULL。可以通过if语句来判断）

②清空内存中的数据（malloc分配的空间里可能存在垃圾值，用memset或bzero 函数清空内存）

```c
void bzero（void *s, int n）;
```

s是 需要置零的空间的起始地址； n是 要置零的数据字节个数。

```c
void memset(void *start, int value, int size);
```

如果要清空空间的首地址为p，value为值，size为字节数。



# [看完这篇还不懂高并发中的线程与线程池你来打我(内含20张图)](https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485705&idx=1&sn=1845875575601b23ed5cea0579c1f77e&source=41#wechat_redirect)

**一切要从CPU说起**

你可能会有疑问，讲多线程为什么要从CPU说起呢？原因很简单，**在这里没有那些时髦的概念，你可以更加清晰的看清问题的本质**。



CPU并不知道线程、进程之类的概念。

CPU只知道两件事:



1. 从内存中取出指令
2. 执行指令，然后回到1



![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya01OPRjgXa0SdjqZD3l3NeZqRcCH7dmA2d6zsPsuiaYrYl72G403n6W2ibwkqwIaibNa5jGFhoibSpPpA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



你看，在这里CPU确实是不知道什么进程、线程之类的概念。



接下来的问题就是CPU从哪里取出指令呢？答案是来自一个被称为Program Counter(简称PC)的寄存器，也就是我们熟知的程序计数器，在这里大家不要把寄存器想的太神秘，你可以简单的把寄存器理解为内存，只不过存取速度更快而已。



PC寄存器中存放的是什么呢？这里存放的是指令在内存中的地址，什么指令呢？是CPU将要执行的下一条指令。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya01OPRjgXa0SdjqZD3l3NeZDIZl58OTQO9l2Id1ULctnkiaTpquPhbp2ZagibbfWz4ZLnG7kyG5gkhw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



那么是谁来设置PC寄存器中的指令地址呢？



原来PC寄存器中的地址默认是自动加1的，这当然是有道理的，因为大部分情况下CPU都是一条接一条顺序执行，当遇到if、else时，这种顺序执行就被打破了，CPU在执行这类指令时会根据计算结果来动态改变PC寄存器中的值，这样CPU就可以正确的跳转到需要执行的指令了。



聪明的你一定会问，那么PC中的初始值是怎么被设置的呢？



在回答这个问题之前我们需要知道CPU执行的指令来自哪里？是来自内存，废话，内存中的指令是从磁盘中保存的可执行程序加载过来的，磁盘中可执行程序是编译器生成的，编译器又是从哪里生成的机器指令呢？答案就是**我们定义的函数**。



![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya01OPRjgXa0SdjqZD3l3NeZfoKd7t7qicMnf9Aq3zX4cMe6OqX4R47JVnGwBDA1u1DdYiabDDU3Y0Yw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



注意是函数，**函数被编译后才会形成CPU执行的指令**，那么很自然的，我们该如何让CPU执行一个函数呢？显然我们只需要找到函数被编译后形成的第一条指令就可以了，第一条指令就是函数入口。



现在你应该知道了吧，我们想要CPU执行一个函数，那么**只需要把该函数对应的第一条机器指令的地址写入PC寄存器就可以了**，这样我们写的函数就开始被CPU执行起来啦。



你可能会有疑问，这和线程有什么关系呢？



**从CPU到操作系统**

上一小节中我们明白了CPU的工作原理，我们想让CPU执行某个函数，那么只需要把函数对应的第一条机器执行装入PC寄存器就可以了，**这样即使没有操作系统我们也可以让CPU执行程序**，虽然可行但这是一个非常繁琐的过程，我们需要：



- 在内存中找到一块大小合适的区域装入程序
- 找到函数入口，设置好PC寄存器让CPU开始执行程序



这两个步骤绝不是那么容易的事情，如果每次在执行程序时程序员自己手动实现上述两个过程会疯掉的，因此聪明的程序员就会想干脆直接写个程序来自动完成上面两个步骤吧。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46kibX9rc6T11I9oAB1jWFk2JemfDDlB9JwNNADnt7xk9fCYhvicRtwlpQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

机器指令需要加载到内存中执行，因此需要记录下内存的起始地址和长度；同时要找到函数的入口地址并写到PC寄存器中，想一想这是不是需要一个数据结构来记录下这些信息：



```c

struct *** {
   void* start_addr;
   int len;
   
   void* start_point;
   ...
};
```



接下来就是起名字时刻。



这个数据结构总要有个名字吧，这个结构体用来记录什么信息呢？记录的是程序在被加载到内存中的运行状态，程序从磁盘加载到内存跑起来叫什么好呢？干脆就叫**进程(Process)**好了，我们的指导原则就是一定要听上去比较神秘，总之大家都不容易弄懂就对了，我将其称为“**弄不懂原则**”。



就这样进程诞生了。



CPU执行的第一个函数也起个名字，第一个要被执行的函数听起来比较重要，干脆就叫**main函数**吧。



完成上述两个步骤的程序也要起个名字，根据“弄不懂原则”这个“简单”的程序就叫**操作系统**(Operating System)好啦。



就这样操作系统诞生了，程序员要想运行程序再也不用自己手动加载一遍了。

现在进程和操作系统都有了，一切看上去都很完美。



**从单核到多核，如何充分利用多核**

人类的一大特点就是生命不息折腾不止，从单核折腾到了多核。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46n2DAESNLuhfOZziboybibJPYMwLmqzjG9qJXufH6plIOwwEqWvCsEfYw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这时，假设我们想写一个程序并且要分利用多核该怎么办呢？



有的同学可能会说不是有进程吗，多开几个进程不就可以了？听上去似乎很有道理，但是主要存在这样几个问题：



- 进程是需要占用内存空间的(从上一节能看到这一点)，如果多个进程基于同一个可执行程序，那么这些进程其内存区域中的内容几乎完全相同，这显然会造成内存的浪费
- 计算机处理的任务可能是比较复杂的，这就涉及到了进程间通信，由于各个进程处于不同的内存地址空间，进程间通信天然需要借助操作系统，这就在增大编程难度的同时也增加了系统开销



该怎么办呢？



**从进程到线程**

让我再来仔细的想一想这个问题，所谓进程无非就是内存中的一段区域，这段区域中保存了**CPU执行的机器指令以及函数运行时的堆栈信息**，要想让进程运行，就把main函数的第一条机器指令地址写入PC寄存器，这样进程就运行起来了。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46DdhEfRkg8vNsh3GYHXX14A7txNlvjHESicVV6W1mtZ5HptWwpAT0YOw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



进程的缺点在于只有一个入口函数，也就是main函数，因此进程中的机器指令**只能被一个CPU执行**，那么有没有办法让多个CPU来执行同一个进程中的机器指令呢？



聪明的你应该能想到，既然我们可以把main函数的第一条指令地址写入PC寄存器，那么其它函数和main函数又有什么区别呢？



答案是没什么区别，main函数的特殊之处无非就在于是CPU执行的第一个函数，除此之外再无特别之处，**我们可以把PC寄存器指向main函数，就可以把PC寄存器指向任何一个函数**。



**当我们把PC寄存器指向非main函数时，线程就诞生了**。



![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46sFSmnmqyFns1prGhZr4gjpSXgYLyddq9FaIcAIQqKDn2shaccaYBHg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



至此我们解放了思想，一个进程内可以有多个入口函数，**也就是说属于同一个进程中的机器指令可以被多个CPU同时执行**。



注意，这是一个和进程不同的概念，创建进程时我们需要在内存中找到一块合适的区域以装入进程，然后把CPU的PC寄存器指向main函数，也就是说进程中只有一个**执行流**。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46gh0lCF1GdcCicvdhB2StPHXFCtoCnEFsLmPfOU2USprlK3LFyQhJchg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

但是现在不一样了，多个CPU可以在同一个屋檐下(进程占用的内存区域)同时执行属于该进程的多个入口函数，也就是说现在一个进程内可以有**多个执行流**了。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46VAvwGrj4VM1iar5D5uNF28DuG1IQDlsiclXybqzoUiaXENNOQ93cyYuag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

总是叫执行流好像有点太容易理解了，再次祭出”弄不懂原则“，起个不容易懂的名字，就叫线程吧。



这就是线程的由来。



操作系统为每个进程维护了一堆信息，用来记录进程所处的内存空间等，这堆信息记为数据集A。



同样的，操作系统也需要为线程维护一堆信息，用来记录线程的入口函数或者栈信息等，这堆数据记为数据集B。



显然数据集B要比数据A的量要少，同时不像进程，创建一个线程时无需去内存中找一段内存空间，**因为线程是运行在所处进程的地址空间的**，这块地址空间在程序启动时已经创建完毕，同时线程是程序在运行期间创建的(进程启动后)，因此当线程开始运行的时候这块地址空间就已经存在了，线程可以直接使用。这就是为什么各种教材上提的创建线程要比创建进程快的原因(当然还有其它原因)。



值得注意的是，有了线程这个概念后，我们只需要进程开启后创建多个线程就可以让所有CPU都忙起来，**这就是所谓高性能、高并发的根本所在**。



很简单，只需要创建出数量**合适**的线程就可以了。

另外值得注意的一点是，由于各个线程共享进程的内存地址空间，因此线程之间的通信无需借助操作系统，这给程序员带来极大方便的同时也带来了无尽的麻烦，多线程遇到的多数问题都出自于线程间通信简直太方便了以至于非常容易出错。**出错的根源在于CPU执行指令时根本没有线程的概念，**多线程编程面临的**互斥**与**同步**问题需要程序员自己解决，关于互斥与同步问题限于篇幅就不详细展开了，大部分的操作系统资料都有详细讲解。



最后需要提醒的是，虽然前面关于线程讲解使用的图中用了多个CPU，但不是说一定要有多核才能使用多线程，在单核的情况下一样可以创建出多个线程，**原因在于线程是操作系统层面的实现，和有多少个核心是没有关系的**，CPU在执行机器指令时也意识不到执行的机器指令属于哪个线程。即使在只有一个CPU的情况下，操作系统也可以通过线程调度让各个线程“同时”向前推进，方法就是将CPU的时间片在各个线程之间来回分配，这样多个线程看起来就是“同时”运行了，但实际上任意时刻还是只有一个线程在运行。



**线程与内存**

在前面的讨论中我们知道了线程和CPU的关系，也就是把CPU的PC寄存器指向线程的入口函数，这样线程就可以运行起来了，这就是为什么我们创建线程时必须指定一个入口函数的原因。无论使用任何编程语言，创建一个线程大体相同：



```c
// 设置线程入口函数DoSomethingthread = CreateThread(DoSomething);
// 让线程运行起来thread.Run();
```

那么线程和内存又有什么关联呢？



我们知道函数在被执行的时产生的数据包括**函数参数**、**局部变量**、**返回地址**等信息，这些信息是保存在栈中的，线程这个概念还没有出现时进程中只有一个执行流，因此只有一个栈，这个栈的栈底就是进程的入口函数，也就是main函数，假设main函数调用了funA，funcA又调用了funcB，如图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46eib3C29qAibeiaL6tOsFACueoCW5OC2uD5MvqRBqXpwnFAs0Uyjl5jZLw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

那么有了线程以后了呢？



有了线程以后一个进程中就存在多个执行入口，即同时存在多个执行流，那么只有一个执行流的进程需要一个栈来保存运行时信息，那么很显然有多个执行流时就需要有多个栈来保存各个执行流的信息，也就是说**操作系统要为每个线程在进程的地址空间中分配一个栈**，即每个线程都有独属于自己的栈，能意识到这一点是极其关键的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya01OPRjgXa0SdjqZD3l3NeZib31FOcaKVzdFFzrE2DpsXQuoF0K6SHYlPkovrZPtlB3RyH7Fklbz6A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



同时我们也可以看到，创建线程是要消耗进程内存空间的，这一点也值得注意。



**线程的使用**

现在有了线程的概念，那么接下来作为程序员我们该如何使用线程呢？

从生命周期的角度讲，线程要处理的任务有两类：长任务和短任务。



**1，长任务，long-lived tasks**

顾名思义，就是任务存活的时间很长，比如以我们常用的word为例，我们在word中编辑的文字需要保存在磁盘上，往磁盘上写数据就是一个任务，那么这时一个比较好的方法就是专门创建一个写磁盘的线程，该写线程的生命周期和word进程是一样的，只要打开word就要创建出该写线程，当用户关闭word时该线程才会被销毁，这就是长任务。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya01OPRjgXa0SdjqZD3l3NeZ0uhfAAscPTq4UAvexj3IH6W5XxQwibeDvibNesFDG4OG6icfsGZcGwNsw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这种场景非常适合创建专用的线程来处理某些特定任务，这种情况比较简单。

有长任务，相应的就有短任务。



**2，短任务，short-lived tasks**

这个概念也很简单，那就是任务的处理时间很短，比如一次网络请求、一次数据库查询等，这种任务可以在短时间内快速处理完成。因此短任务多见于各种Server，像web server、database server、file server、mail server等，这也是互联网行业的同学最常见的场景，这种场景是我们要重点讨论的。



这种场景有两个特点：一个是**任务处理所需时间短**；另一个是**任务数量巨大**。



如果让你来处理这种类型的任务该怎么办呢？



你可能会想，这很简单啊，当server接收到一个请求后就创建一个线程来处理任务，处理完成后销毁该线程即可，So easy。



这种方法通常被称为thread-per-request，也就是说来一个请求就创建一个线程：

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46Zf1QRsl8ibsDWQ4mn1xNXmEJlicYPWyQCEiao4OJCL7xLbIqN5O8qwxfA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

如果是长任务，那么这种方法可以工作的很好，但是对于大量的短任务这种方法虽然实现简单但是有这样几个缺点：



\1. 从前几节我们能看到，线程是操作系统中的概念(这里不讨论用户态线程实现、协程之类)，因此创建线程天然需要借助操作系统来完成，操作系统创建和销毁线程是需要消耗时间的

\2. 每个线程需要有自己独立的栈，因此当创建大量线程时会消耗过多的内存等系统资源



这就好比你是一个工厂老板(想想都很开心有没有)，手里有很多订单，每来一批订单就要招一批工人，生产的产品非常简单，工人们很快就能处理完，处理完这批订单后就把这些千辛万苦招过来的工人辞退掉，当有新的订单时你再千辛万苦的招一遍工人，干活儿5分钟招人10小时，如果你不是励志要让企业倒闭的话大概是不会这么做到的，因此一个更好的策略就是招一批人后就地养着，有订单时处理订单，没有订单时大家可以闲呆着。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/8g3rwJPmya01OPRjgXa0SdjqZD3l3NeZgial8MhhO4njGI3WOgTy2ZSMwVueWzly2wHTiaPHPIedtPOVXYR8vrCQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这就是线程池的由来。



**从多线程到线程池**

线程池的概念是非常简单的，无非就是创建一批线程，之后就不再释放了，有任务就提交给这些线程处理，因此无需频繁的创建、销毁线程，同时由于线程池中的线程个数通常是固定的，也不会消耗过多的内存，因此这里的思想就是**复用、可控**。



**线程池是如何工作的**

可能有的同学会问，该怎么给线程池提交任务呢？这些任务又是怎么给到线程池中线程呢？



很显然，数据结构中的队列天然适合这种场景，提交任务的就是生产者，消费任务的线程就是消费者，实际上这就是经典的**生产者-消费者问题**。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya01OPRjgXa0SdjqZD3l3NeZR4fttkLbGLSWibqLiaaWYAlzQPDobSBZmEpkYH7ibyeteHpjp9RltBb1A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

现在你应该知道为什么操作系统课程要讲、面试要问这个问题了吧，因为如果你对生产者-消费者问题不理解的话，本质上你是无法正确的写出线程池的。



限于篇幅在这里博主不打算详细的讲解生产者消费者问题，参考操作系统相关资料就能获取答案。这里博主打算讲一讲一般提交给线程池的任务是什么样子的。



一般来说提交给线程池的任务包含两部分：1) **需要被处理的数据**；2) **处理数据的函数**



```c

struct task {
    void* data;     // 任务所携带的数据
    handler handle; // 处理数据的方法
}
```

(注意，你也可以把代码中的struct理解成class，也就是对象。)

线程池中的线程会阻塞在队列上，当生产者向队列中写入数据后，线程池中的某个线程会被唤醒，该线程从队列中取出上述结构体(或者对象)，以结构体(或者对象)中的数据为参数并调用处理函数：



```c

while(true) {
  struct task = GetFromQueue(); // 从队列中取出数据
  task->handle(task->data);     // 处理数据
}
```

以上就是线程池最**核心**的部分。

理解这些你就能明白线程池是如何工作的了。



**线程池中线程的数量**

现在线程池有了，那么线程池中线程的数量该是多少呢？

在接着往下看前先自己想一想这个问题。



如果你能看到这里说明还没有睡着。



要知道线程池的线程过少就不能充分利用CPU，线程创建的过多反而会造成系统性能下降，内存占用过多，线程切换造成的消耗等等。因此线程的数量既不能太多也不能太少，那到底该是多少呢？



回答这个问题，你需要知道线程池处理的任务有哪几类，有的同学可能会说你不是说有两类吗？长任务和短任务，这个是从生命周期的角度来看的，那么从处理任务所需要的资源角度看也有两种类型，这就是没事儿找抽型和。。啊不，是CPU密集型和I/O密集型。



**1，CPU密集型**

所谓CPU密集型就是说处理任务不需要依赖外部I/O，比如科学计算、矩阵运算等等。在这种情况下只要线程的数量和核数基本相同就可以充分利用CPU资源。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46CVbA8UH1f6cue7K1miczK55O1qvcicLajATia4Pvbm2fiaibWSSrzCpwNiaw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



**2，I/O密集型**

这一类任务可能计算部分所占用时间不多，大部分时间都用在了比如磁盘I/O、网络I/O等。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya005X0O39iaAaeRTmXYkdZ46SQCUJ4kicyCynn5M6qqCGDscXl0WITscSmia8Z8SApicHsJmIEGYhD1qA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

这种情况下就稍微复杂一些了，你需要利用性能测试工具评估出用在I/O等待上的时间，这里记为WT(wait time)，以及CPU计算所需要的时间，这里记为CT(computing time)，那么对于一个N核的系统，合适的线程数大概是N * (1 + WT/CT)，假设I/O等待时间和计算时间相同，那么你大概需要2N个线程才能充分利用CPU资源，注意这只是一个理论值，具体设置多少需要根据真实的业务场景进行测试。



当然充分利用CPU不是唯一需要考虑的点，随着线程数量的增多，内存占用、系统调度、打开的文件数量、打开的socker数量以及打开的数据库链接等等是都需要考虑的。



因此这里没有万能公式，要**具体情况具体分析**。



**线程池不是万能的**

线程池仅仅是多线程的一种使用形式，因此多线程面临的问题线程池同样不能避免，像死锁问题、race condition问题等等，关于这一部分同样可以参考操作系统相关资料就能得到答案，所以基础很重要呀老铁们。



**线程池使用的最佳实践**

线程池是程序员手中强大的武器，互联网公司的各个server上几乎都能见到线程池的身影，使用线程池前你需要考虑：



- 充分理解你的任务，是长任务还是短任务、是CPU密集型还是I/O密集型，如果两种都有，那么一种可能更好的办法是把这两类任务放到不同的线程池中，这样也许可以更好的确定线程数量
- 如果线程池中的任务有I/O操作，那么务必对此任务设置超时，否则处理该任务的线程可能会一直阻塞下去
- 线程池中的任务最好不要**同步**等待其它任务的结果



**总结**

本节我们从CPU开始一路来到常用的线程池，从底层到上层、从硬件到软件。注意，这里通篇没有出现任何特定的编程语言，线程不是语言层面的概念(依然不考虑用户态线程)，但是当你真正理解了线程后，相信你可以在任何一门语言下用好多线程，你需要理解的是道，此后才是术。



# [内存管理：程序是如何被优雅的装载到内存中](https://mp.weixin.qq.com/s?__biz=MzUxMjEyNDgyNw==&mid=2247499719&idx=2&sn=6d3405bec456cbcb9e4ffe813ac24020&chksm=f96b8d33ce1c0425e0cf586aa08739266ef9ecf3f9f0063683ae48bffaed4d468ff3fac6a5e7&mpshare=1&scene=24&srcid=1119qxcAShTVkya1qsYy0P8D&sharer_sharetime=1637316262457&sharer_shareid=0d5c82ce3c8b7c8f30cc9a686416d4a8#rd)

内存作为计算机中一项比较重要的资源，它的主要作用就是解决CPU和磁盘之间速度的鸿沟，但是由于内存条是需要插入到主板上的，因此对于一台计算机来说，由于物理限制，它的内存不可能无限大的。我们知道我们写的代码最终是要从磁盘被加载到内存中的，然后再被CPU执行，不知道你有没有想过，为什么一些大型游戏大到10几G，却可以在只有8G内存的电脑上运行？甚至在玩游戏期间，我们还可以聊微信、听音乐...，这么多进程看着同时在运行，它们在内存中是如何被管理的？带着这些疑问我们来看看计算系统内存管理那些事。

## 内存的交换技术

如果我们的内存可以无限大，那么我们担忧的问题就不会存在，但是实际情况是往往我们的机器上会同时运行多个进程，这些进程小到需要几十兆内存，大到可能需要上百兆内存，当许许多多这些进程想要同时加载到内存的时候是不可能的，但是从我们用户的角度来看，似乎这些进程确实都在运行呀，这是怎么回事？

这就引入要说的**交换技术**了，从字面的意思来看，我想你应该猜到了，它会把某个内存中的进程交换出去。当我们的进程空闲的时候，其他的进程又需要被运行，然而很不幸，此时没有足够的内存空间了，这时候怎么办呢？似乎刚刚那个空闲的进程有种占着茅坑不拉屎的感觉，于是可以把这个空闲的进程从内存中交换到磁盘上去，这时候就会空出多余的空间来让这个新的进程运行，当这个换出去的空闲进程又需要被运行的时候，那么它就会被再次交换进内存中。通过这种技术，可以让有限的内存空间运行更多的进程，进程之间不停来回交换，看着好像都可以运行。![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWush6ia3RkqU0jCPkxMjqjunETKgBqm4aKUnyTibyibghkNCwnyD0CdM31g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)如图所示，一开始进程A被换入内存中，所幸还剩余的内存空间比较多，然后进程B也被换入内存中，但是剩余的空间比较少了，这时候进程C想要被换入到内存中，但是发现空间不够了，这时候会把已经运行一段时间的进程A换到磁盘中去，然后调入进程C。![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuCic9sKAjiaDLP9VPDw9lAJbpJOVfDpIkOGQPBmsccoHDQHTGiamKKoorg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 内存碎片

通过这种交换技术，交替的换入和换出进程可以达到小内存可以运行更多的进程，但是这似乎也产生了一些问题，不知道你发现了没有，在进程C换入进来之后，在进程B和进程C之间有段较小的内存空间，并且进程B之上也有段较小的内存空间，说实话，这些小空间可能永远没法装载对应大小的程序，那么它们就浪费了，在某些情况下，可能会产生更多这种内存碎片。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWukJYSFIBrZmrjhj1tc3nQlbmIJNOKibcc31xNdaPkCGEmjWicXV43G14w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)如果想要节约内存，那么就得用到**内存紧凑**的技术了，即把所有的进程都向下移动，这样所有的碎片就会连接在一起变成一段更大的连续内存空间了。![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWua5uHxk3zKzBvpRc18RicpLWtR1XtHBE5t64xqPOslVv8PiaaIicClwouw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)但是这个移动的开销基本和当前内存中的活跃进程成正比，据统计，一台16G内存的计算机可以每8ns复制8个字节，它紧凑全部的内存大概需要16s，所以通常不会进行紧凑这个操作，因为它耗费的CPU时间还是比较大的。

### 动态增长

其实上面说的进程装载算是比较理想的了，正常来说，一个进程被创建或者被换入的时候，它占用多大的空间就分配多大的内存，但是如果我们的进程需要的空间是动态增长的，那就麻烦了，比如我们的程序在运行期间的**for循环**可能会利用到某个临时变量来存放目标数据（例如以下变量a，随着程序的运行是会越来越大的）：

```
var a []int64
for i:= 0;i <= 1000000;i++{
  if i%2 == 0{
   a = append(a,i) //a是不断增大的
  }
}
```

当需要增长的时候：

1. 如果进程的邻居是**空闲区**那还好，可以把该空闲区分配给进程
2. 如果进程的邻居是另一个进程，那么解决的办法只能把增长的进程移动到一个更大的空闲内存中，但是万一没有更大的内存空间，那么就要触发换出，把一个或者多个进程换出去来提供更多的内存空间，很明显这个开销不小。

为了解决进程空间动态增长的问题，我们可以提前多给一些空间，比如进程本身需要10M，我们多给2M，这样如果进程发生增长的时候，可以利用这2M空间，当然前提是这2M空间够用，如果不够用还是得触发同样的移动、换出逻辑。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWu9uT76NOrpia0hliac1kw6s0mmWezsTp2jiacPicAgcZlMdhvMM3fMia6oTg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 空闲的内存如何管理

前面我们说到内存的交换技术，交换技术的目的是腾出空闲内存来，那么我们是如何知道一块内存是被使用了，还是空闲的？因此需要一套机制来区分出空闲内存和已使用内存，一般操作系统对内存管理的方式有两种：**位图法**和**链表法**。

### 位图法

先说位图法，没错，位图法采用比特位的方式来管理我们的内存，每块内存都有位置，我们用一个比特位来表示：

1. 如果某块内存被使用了，那么比特位为**1**
2. 如果某块内存是空闲的，那么比特位为**0**

这里的某块内存具体是多大得看操作系统是如何管理的，它可能是一个字节、几个字节甚至几千个字节，但是这些不是重点，重点是我们要知道内存被这样分割了。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWumn0nhXfW9bmiatz8wVicWCFt8k8GF6qjXuPXmqia73vPGyYmYdlar123w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)位图法的优点就是清晰明确，某个内存块的状态可以通过位图快速的知道，因为它的时间复杂度是O(1)，当然它的缺点也很明显，就是需要占用太多的空间，尤其是管理的内存块越小的时候。更糟糕的是，进程分配的空间不一定是内存块的整数倍，那么最后一个内存块中一定是有浪费的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuZHZ4djPibKCEicgRF8rLiaPV5j1FhfanJv7z14GwtqrRzOTHwRiccM4nsA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

如图，进程A和进程B都占用的最后一个内存块的一部分，那么对于最后一个内存块，它的另一部分一定是浪费的。

### 链表法

相比位图法，链表法对空间的利用更加合理，我相信你应该已经猜到了，链表法简单理解就是把使用的和空闲的内存用链表的方式连接起来，那么对于每个链表的元素节点来说，他应该具备以下特点：

1. 应该知道每个节点是空闲的还是被使用的
2. 每个节点都应该知道当前节点的内存的开始地址和结束地址

针对这些特点，最终内存对应的链表节点大概是这样的：

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuSRCfnAPMJ2UqcDTvj7H2hbicOtCqhYHBmcPgKntZvAPQicrGYsogSdJg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)**p**代表这个节点对应的内存空间是被使用的，**H**代表这个节点对应的内存空间是空闲的，**start**代表这块内存空间的开始地址，**length**代表的是这块内存的长度，最后还有指向邻居节点的pre和next**指针**。

因此对于一个进程来说，它与邻居的组合有四种：

1. 它的前后节点都不是空闲的
2. 它的前一个节点是空闲的，它的后一个节点也不是空闲的
3. 它的前一个节点不是空闲的，它的后一个节点是空闲的
4. 它的前后节点都是空闲的

当一个内存节点被换出或者说进程结束后，那么它对应的内存就是空闲的，此时如果它的邻居也是空闲的，就会发生合并，即两块空闲的内存块**合并**成一个大的空闲内存块。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWu7oHvTpOL6hHRkZL51xfyCIJvYu2Tn4icdKUgTyKO1h4hdhRgBuRaicGw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

ok，通过链表的方式把我们的内存给管理起来了，接下来就是当创建一个进程或者从磁盘换入一个进程的时候，如何从链表中找到一块合适的内存空间？

##### 首次适应算法

其实想要找到空闲内存空间最简单的办法就是顺着链表找到**第一个**满足需要内存大小的节点，如果找到的第一个空闲内存块和我们需要的内存空间是一样大小的，那么就直接利用，但是这太理想了，现实情况大部分可能是找到的第一个目标内存块要比我们的需要的内存空间要大一些，这时候呢，会把这个空闲内存空间分成两块，一块正好使用，一块继续充当空闲内存块。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuaLhOasNyRl3OOylyKm4ARAXaksGibnnhemuFU8vDtEdH89FqZ2Lribtw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)一个需要3M内存的进程，会把4M的空间拆分成3M和1M。

##### 下次适配算法

和首次适应算法很相似，在找到目标内存块后，会记录下位置，这样下次需要再次查找内存块的时候，会从这个位置开始找，而不用从链表的头节点开始寻找，这个算法存在的问题就是，如果标记的位置之前有合适的内存块，那么就会被跳过。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuSicndo9p8w6CXbpbVgxwRdwibDdjAo760Az0Zt4IM5VXm0aFiaLxG6pcA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)一个需要2M内存的进程，在5这个位置找到了合适的空间，下次如果需要这1M的内存会从5这个位置开始，然后会在7这个位置找到合适的空间，但是会跳过1这个位置。

##### 最佳适配算法

相比首次适应算法，最佳适配算法的区别就是：不是找到第一个合适的内存块就停止，而是会继续向后找，并且每次都可能要检索到链表的尾部，因为它要找到最合适那个内存块，什么是最合适的内存块呢？如果刚好大小一致，则一定是最合适的，如果没有大小一致的，那么能容得下进程的那个最小的内存块就是最合适的，可以看出最佳适配算法的平均检索时间相对是要慢的，同时可能会造成很多小的碎片。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWumIOecMQJibCp4nCnDCuiaQyhvXYkrksh72CrDUDgKIGNuiaherhB6lTPQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)假设现在进程需要2M的内存，那么最佳适配算法会在检索到3号位置（3M）后，继续向后检索，最终会选择5号位置的空闲内存块。

##### 最差适配算法

我们知道最佳适配算法中最佳的意思是找到一个最贴近真实大小的空闲内存块，但是这会造成很多细小的碎片，这些细小的碎片一般情况下，如果没有进行内存紧凑，那么大概率是浪费的，为了避免这种情况，就出现了这个最差适配算法，这个算法它和最佳适配算法是反着来的，它每次尝试分配最大的可用空闲区，因为这样的话，理论上剩余的空闲区也是比较大的，内存碎片不会那么小，还能得到重复利用。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWu6DAqWoZhibxXUftqgWIqq50Y2ibun7Q2DQypUbCFljibnqmB1hKs8DCFw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)一个需要1.5M的进程，在最差适配算法情况下，不会选择3号（2M）内存空闲块，而是会选择更大的5号（3M）内存空闲块。

##### 快速适配算法

上面的几种算法都有一个共同的特点：空闲内存块和已使用内存块是共用的一个链表，这会有什么问题呢？正常来说，我要查找一个空闲块，我并不需要检索已经被使用的内存块，所以如果能把已使用的和未使用的分开，然后用两个链表分别维护，那么上面的算法无论哪种，速度都将得到提升，并且节点也不需要P和M来标记状态了。但是分开也有缺点，如果进程终止或者被换出，那么对应的内存块需要从已使用的链表中删掉然后加入到未使用的链表中，这个开销是要稍微大点的。当然对于未使用的链表如果是排序的，那么首次适应算法和最佳适应算法是一样快的。

快速适配算法就是利用了这个特点，这个算法会为那些常用大小的空闲块维护单独的链表，比如有4K的空闲链表、8K的空闲链表...，如果要分配一个7K的内存空间，那么既可以选择两个4K的，也可以选择一个8K的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuNwKXLUwHl868QjiaOUPy10QPNliaAJpYXz49p8JSW0gw3LEicQDjsAJDQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)它的优点很明显，在查找一个指定大小的空闲区会很快速，但是一个进程终止或被换出时，会寻找它的相邻块查看是否可以合并，这个过程相对较慢，如果不合并的话，那么同样也会产生很多的小空闲区，它们可能无法被利用，造成浪费。

## 虚拟内存：小内存运行大程序

可能你看到小内存运行大程序比较诧异，因为上面不是说到了吗？只要把空闲的进程换出去，把需要运行的进程再换进来不就行了吗？内存交换技术似乎解决了，这里需要注意的是，首先内存交换技术在空间不够的情况下需要把进程换出到磁盘上，然后从磁盘上换入新进程，看到磁盘你可能明白了，很慢。其次，你发现没，**换入换出的是整个进程**，我们知道进程也是由一块一块代码组成的，也就是许许多多的机器指令，对于内存交换技术来说，**一个进程下的所有指令要么全部进内存，要么全部不进内存**。看到这里你可能觉得这不是正常吗？好的，别急，我们接着往下看。

后来出现了更牛逼的技术：**虚拟内存**。它的基本思想就是，每个程序拥有自己的地址空间，尤其注意后面的自己的地址空间，然后这个空间可以被分割成多个块，每一个块我们称之为**页**（page）或者叫页面，对于这些页来说，它们的地址是连续的，同时它们的地址是虚拟的，并不是真正的物理内存地址，那怎么办？程序运行需要读到真正的物理内存地址，别跟我玩虚的，这就需要一套映射机制，然后**MMU**出现了，MMU全称叫做：Memory Managment Unit，即内存管理单元，正常来说，CPU读某个内存地址数据的时候，会把对应的地址发到内存总线上，但是在虚拟内存的情况下，直接发到内存总线上肯定是找不到对应的内存地址的，这时候CPU会把虚拟地址告诉MMU，让MMU帮我们找到对应的内存地址，没错，MMU就是一个地址转换的中转站。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuc6VoR3ZVtoPf4iaKMiaU4UV3ASbia8t2nicJOyZvaqL0XhO9nsiaCk3Za1w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

程序地址分页的好处是：

1. 对于程序来说，不需要像内存交换那样把所有的指令都加载到内存中才能运行，可以单独运行某一页的指令
2. 当进程的某一页不在内存中的时候，CPU会在这个页加载到内存的过程中去执行其他的进程。

当然虚拟内存会分页，那么对应的物理内存其实也会分页，只不过物理内存对应的单元我们叫**页框**。页面和页框通常是一样大的。我们来看个例子，假设此时页面和页框的大小都是4K，那么对于64K的虚拟地址空间可以得到64/4=16个虚拟页面，而对于32K的物理地址空间可以得到32/4=8个页框，很明显此时的页框是不够的，总有些虚拟页面找不到对应的页框。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuib28hkKfL6Rm2ZW1GEN2mp8wf3SQmpw7BQvwE4CHwFic0UCRAPZBLTDw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

我们先来看看虚拟地址为20500对应物理地址如何被找到的：

1. 首先虚拟地址20500对应5号页面（20480-24575）
2. 5号页面的起始地址20480向后查找20个字节，就是虚拟地址的位置
3. 5号页面对应3号物理页框
4. 3号物理页框的起始地址是12288，12288+20=12308，即12308就是我们实际的目标物理地址。

但是对于虚拟地址而言，图中还有红色的区域，上面我们也说到了，总有些虚拟地址没有对应的页框，也就是这部分虚拟地址是没有对应的物理地址，当程序访问到一个未被映射的虚拟地址（红色区域）的时候，那么就会发生**缺页中断**，然后操作系统会找到一个最近很少使用的页框把它的内容换到磁盘上去，再把刚刚发生缺页中断的页面从磁盘读到刚刚回收的页框中去，最后修改虚拟地址到页框的映射，然后重启引起中断的指令。

最后可以发现分页机制使我们的程序更加细腻了，运行的粒度是页而不是整个进程，大大提高了效率。

### 页表

上面说到虚拟内存到物理内存有个映射，这个映射我们知道是MMU做的，但是它是如何实现的？最简单的办法就是需要有一张类似hash表的结构来查看，比如页面1对应的页框是10，那么就记录成`hash[1]=10`，但是这仅仅是定位到了页框，具体的位置还没定位到，也就是类似偏移量的数据没有。不猜了，我们直接来看看MMU是如何做到的，以一个16位的虚拟地址，并且页面和页框都是4K的情况来说，MMU会把前4位当作是索引，也就是定位到页框的序号，后12位作为偏移量，这里为什么是12位，很巧妙，因为2^12=4K，正好给每个页框里的数据上了个标号。因此我们只需要根据前4位找到对应的页框即可，然后偏移量就是后12位。找页框就是去我们即将要说的**页表**里去找，页表除了有页面对应的页框后，还有个标志位来表示对应的页面是否有映射到对应的页框，缺页中断就是根据这个标志位来的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWuT8ricc9UP7JdI5x69J4tiaLFHfYT0u1rOVBV9xsF3yEowvgIdJaoQib6A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

可以看出页表非常关键，不仅仅要知道页框、以及是否缺页，其实页表还有**保护位**、**修改位**、**访问位**和**高速缓存禁止位**。

- 保护位：指的是一个页允许什么类型的访问，常见的是用三个比特位分别表示**读**、**写**、**执行**。
- 修改位：有时候也称为脏位，由硬件自动设置，当一个页被修改后，也就是和磁盘的数据不一致了，那么这个位就会被标记为1，下次在页框置换的时候，需要把脏页刷回磁盘，如果这个页的标记为0，说明没有被修改，那么不需要刷回磁盘，直接把数据丢弃就行了。
- 访问位：当一个页面不论是发生读还是发生写，该页面的访问位都会设置成1，表示正在被访问，它的作用就是在发生缺页中断时，根据这个标志位优先在那些没有被访问的页面中选择淘汰其中的一个或者多个页框。
- 高速缓存禁止位：对于那些映射到设备寄存器而不是常规内存的页面而言，这个特性很重要，加入操作系统正在紧张的循环等待某个IO设备对它刚发出的指令做出响应，保证这个设备读的不是被高速缓存的副本非常重要。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWu5aElichZO9UUooC16TenNTwv06GvEsez1DtLW5coj4AKSN8LvAM2s4g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### TLB快表加速访问

通过页表我们可以很好的实现虚拟地址到物理地址的转换，然而现代计算机至少是32位的虚拟地址，以4K为一页来说，那么对于32位的虚拟地址，它的页表项就有2^20=1048576个，无论是页表本身的大小还是检索速度，这个数字其实算是有点大了。如果是64位虚拟的地址，按照这种方式的话，页表项将大到超乎想象，更何况最重要的是**每个进程都会有一个这样的页表**。

我们知道如果每次都要在庞大的页表里面检索页框的话，效率一定不是很高。而且计算机的设计者们观察到这样一种现象：**大多数程序总是对少量的页进行多次访问**，如果能为这些经常被访问的页单独建立一个查询页表，那么速度就会大大提升，这就是**快表**，快表只会包含少量的页表项，通常不会超过256个，当我们要查找一个虚拟地址的时候。首先会在快表中查找，如果能找到那么就可以直接返回对应的页框，如果找不到才会去页表中查找，然后从快表中淘汰一个表项，用新找到的页替代它。

总体来说，TLB类似一个体积更小的页表缓存，它存放的都是最近被访问的页，而不是所有的页。

## 多级页表

TLB虽然一定程度上可以解决转换速度的问题，但是没有解决页表本身占用太大空间的问题。其实我们可以想想，大部分程序会使用到所有的页面吗？其实不会。一个进程在内存中的地址空间一般分为程序段、数据段和堆栈段，堆栈段在内存的结构上是从高地址向低地址增长的，其他两个是从低地址向高地址增长的。

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWux0lfD9WXexLhPXTHfz51qXdibv67foacFdf4kFeNAP2zZ9IiasBcL4wA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

可以发现中间部分是空的，也就是这部分地址是用不到的，那我们完全不需要把中间没有被使用的内存地址也引入页表呀，这就是多级页表的思想。以32位地址为例，后12位是偏移量，前20位可以拆成两个10位，我们暂且叫做顶级页表和二级页表，每10位可以表示2^10=1024个表项，因此它的结构大致如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/WUHAvRwQMxqYwM80nxcbksRibSkUiareWurRDLHcP7ibdY8UkmDDhFovYkE5VDdibWHibWo9se7R6PYaCsMRy3HDjKg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)对于顶级页表来说，中间灰色的部分就是没有被使用的内存空间。顶级页表就像我们身份证号前面几个数字，可以定位到我们是哪个城市或者县的，二级页表就像身份证中间的数字，可以定位到我们是哪个街道或者哪个村的，最后的偏移量就像我们的门牌号和姓名，通过这样的分段可以大大减少空间，我们来看个简单的例子：

**如果我们不拆出顶级页表和二级页表，那么所需要的页表项就是2^20个，如果我们拆分，那么就是1个顶级页表+2^10个二级页表**，两者的存储差距明显可以看出拆分后更加节省空间，这就是多级页表的好处。

当然我们的二级也可以拆成三级、四级甚至更多级，级数越多灵活性越大，但是级数越多，检索越慢，这一点是需要注意的。



